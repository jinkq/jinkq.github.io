

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/微信图片_20220916104850.jpg">
  <link rel="icon" href="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/微信图片_20220916104850.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="冰柠果儿">
  <meta name="keywords" content="">
  
    <meta name="description" content="基本假设，BLUE，评价指标">
<meta property="og:type" content="article">
<meta property="og:title" content="线性回归">
<meta property="og:url" content="http://example.com/2023/03/03/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/index.html">
<meta property="og:site_name" content="冰柠果儿">
<meta property="og:description" content="基本假设，BLUE，评价指标">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20210623153310.png">
<meta property="og:image" content="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20210623153537.png">
<meta property="article:published_time" content="2023-03-03T06:28:36.465Z">
<meta property="article:modified_time" content="2023-05-08T02:36:26.984Z">
<meta property="article:author" content="冰柠果儿">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20210623153310.png">
  
  
  
  <title>线性回归 - 冰柠果儿</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"♪","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"U9LIqIC6h4LdIbHbvS9engTE-9Nh9j0Va","app_key":"nMLuYyOqdaWa1PXufJuNqFGn","server_url":"https://u9liqic6.lc-cn-e1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>冰柠果儿</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="线性回归"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-03-03 14:28" pubdate>
          2023年3月3日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          15k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          123 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">线性回归</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="线性回归">线性回归</h1>
<h2 id="基本假设">基本假设</h2>
<ol type="1">
<li><p>The Two Variables Should be in a <strong>Linear</strong>
Relationship</p>
<ul>
<li>检验方法：散点图scatter plot</li>
<li>解决：According to the characteristics of the data, perform
non-linear transformation on the independent/dependent variables. For
example, take square, cubic, logarithmic, etc</li>
</ul></li>
<li><p>residuals follow <strong>normal distribution</strong></p>
<ul>
<li>检验方法：QQ图（quantile of target distribution and sample
distribution, if the data points are distributed near the straight line
y=x)或ks检验</li>
<li>影响：置信区间会变得很不稳定</li>
<li>解决：
<ul>
<li>寻找遗漏的自变量</li>
<li>检验并剔除异常值</li>
<li>对自变量和/或因变量进行非线性变换</li>
</ul></li>
</ul></li>
<li><p>There Should be No <strong>Multicollinearity</strong> in the
Data多重共线性</p>
<ul>
<li>Independent variables shall be independent of each other</li>
<li>检验方法：
<ul>
<li>VIF (variance inflation factor)(&lt;10 is ok), <span
class="math inline">\(VIF=\frac{1}{1-R^2}\)</span>，<span
class="math inline">\(R^2\)</span> is the multiple correlation
coefficient of linear regression with this variable as the dependent
variable and the other variables as the independent variables. 表示It
represents the variance of the regression coefficient estimator over the
variance when the independent variables without multicollinearity</li>
<li>correlation matrix (&gt;0.8)【VIF和corr有关，VIF =
皮尔逊相关系数矩阵的余子式/皮尔逊相关系数矩阵的行列式】</li>
</ul></li>
<li>影响：
<ul>
<li>high correlated: variance of estimate be larger，矩阵<span
class="math inline">\((X^TX)\)</span>几乎不可逆，<span
class="math inline">\((X^TX)^{-1}\)</span>变得很大，使得方差<span
class="math inline">\(Var(\hat{\beta}|X)=\sigma^2(X^TX)^{-1}\)</span>增大，系数估计不准确；X中元素轻微变化就会引起<span
class="math inline">\((X^TX)^{-1}\)</span>很大变化，导致OLS估计值<span
class="math inline">\(\hat{\beta}\)</span>发生很大变化</li>
<li>strict correlated: The rank of the X will be smaller than the number
of independent variables, making (XTX) irreversible, the estimate has no
solution</li>
</ul></li>
<li>解决：
<ul>
<li>For highly correlated independent variables, only reserve one of
them</li>
<li>PCA</li>
<li>Ridge/LASSO</li>
<li>如不关心具体的回归系数，只关心整个方程的预测能力，可不必理会多重共线性。多重共线性的主要后果是使得对单个变量的贡献估计不准，但所有变量的整体效应仍可较准确地估计</li>
<li>如关心具体的回归系数，但多重共线性并不影响所关心变量的显著性，也可不必理会。在方差膨胀的情况下，系数依然显著；如没有多重共线性，只会更显著</li>
<li>如多重共线性影响所关心变量的显著性，应设法进行处理。如增大样本容量，剔除导致严重共线性的变量，将变量标准化，或对模型设定进行修改</li>
</ul></li>
</ul></li>
<li><p>There Should be No <strong>Autocorrelation</strong> in the
Data自相关性</p>
<ul>
<li><p>The residuals should be independent of each
other.扰动项方差矩阵非主对角线（main diagonal）元素不为0</p></li>
<li><p>检验方法：DW Statistics</p>
<ul>
<li>BG检验：
<ul>
<li>思路：扰动项存在阶自相关→p阶自回归方程系数不全为零→<span
class="math inline">\(\varepsilon_i\)</span>不可观测，用<span
class="math inline">\(e_i\)</span>替代进行辅助回归→因为残差是解释变量的函数，还需要在辅助回归中引入解释变量</li>
<li>原假设：<span
class="math inline">\(H_0:\gamma_1=...=\gamma_p=0\)</span></li>
<li>辅助回归：<span
class="math inline">\(e_t=\gamma_1e_{t-1}+...+\gamma_pe_{t-p}+\delta_2x_{t2}+...+\delta_Kx_{tK}+v_t(t=p+1,...,n)\)</span></li>
<li>LM检验：<span
class="math inline">\(LM=(n-p)R^2\xrightarrow{d}\mathcal{X}^2(p)\)</span></li>
</ul></li>
</ul></li>
<li><p>影响：【自相关不影响无偏性、一致性、渐进正态】Reduce the accuracy
of the model，普通标准误的t检验、F检验失效，不是BLUE</p></li>
<li><p>解决：</p>
<ul>
<li><p>GLS</p></li>
<li><p>ARIMA</p></li>
<li><p>CO估计法：</p>
<ol type="1">
<li><p>假设扰动项<span
class="math inline">\(\varepsilon_t\)</span>存在自相关，为一阶自回归形式<span
class="math inline">\(\varepsilon_t=\rho\varepsilon_{t-1}+u_t\)</span>，<span
class="math inline">\(u_t\)</span>为白噪声</p></li>
<li><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20210623153310.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" /></p>
<p>新扰动项<span
class="math inline">\((\varepsilon_t-\rho\varepsilon_{t-1})=u_t\)</span>为白噪声</p></li>
<li><p>对方程（8.14）进行OLS估计，但损失一个样本容量，仍不是BLUE</p></li>
<li><p>补上一个方程</p>
<p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20210623153537.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" /></p></li>
</ol></li>
</ul></li>
</ul></li>
<li><p>There Should be <strong>Homoscedasticity</strong> Among the
Data同方差性</p>
<ul>
<li><p>The variance of the residuals should be
constant，扰动项方差矩阵主对角线元素不相等</p></li>
<li><p>检验方法：White Test</p>
<ul>
<li>BP检验：
<ul>
<li>思路：存在异方差→<span
class="math inline">\(\varepsilon_i\)</span>对<span
class="math inline">\(x_i\)</span>的回归系数不全为0→扰动项<span
class="math inline">\(\varepsilon_i^2\)</span>不可观测，用残差平方<span
class="math inline">\(e^2_i\)</span>代替进行辅助回归</li>
<li>原假设：<span
class="math inline">\(H_0:\delta_2=...=\delta_K=0\)</span></li>
<li>辅助回归：<span
class="math inline">\(e_i^2=\delta_1+\delta_2x_{i2}+...+\delta_Kx_{iK}+error_i\)</span></li>
<li>LM检验：<span
class="math inline">\(LM=nR^2\xrightarrow{d}\mathcal{X}^2(K-1)\)</span></li>
</ul></li>
<li>White检验：
<ul>
<li>思路：BP检验假设条件方差函数为线性函数，可能忽略了高次项。在BP检验的辅助回归中加入所有二次项（平方项和交叉项）</li>
<li>辅助回归：<span
class="math inline">\(e_i^2=\delta_1+\delta_2x_{i2}+\delta_3x_{i3}+\delta_4x_{i2}^2+\delta_5x_{i3}^2+\delta_6x_{i2}x_{i3}+error_i\)</span></li>
<li>优点：可检验任何形式的异方差；因为根据泰勒展开式，二次函数可很好地逼近任何光滑函数</li>
<li>缺点：如果解释变量较多，则解释变量的二次项将更多，在辅助回归中将损失较多样本容量</li>
</ul></li>
</ul></li>
<li><p>影响：【异方差不影响无偏性、渐进正态】，估计不有效，误差较大，普通标准误的t检验、F检验失效，不是BLUE</p></li>
<li><p>解决：</p>
<ul>
<li><p>使用稳健回归。即，不实用最小二乘法的平方和形式的目标函数，从而降低了残差方差较大的数据点对参数估计的影响。</p></li>
<li><p>使用加权回归。即，根据每个数据点的拟合值的方差为每个数据点分配一个权重，给予较高方差的数据点较小的权重，从而缩小残差和</p></li>
<li><p>WLS：方差较小的观测值包含的信息量较大，给予方差较小的观测值较大的权重，然后进行加权最小二乘法估计。通过变量转换，使得变换后的模型满足球形扰动项的假定(变为同方差)，然后进行OLS
估计</p>
<p>步骤：</p>
<ol type="1">
<li>假设异方差形式为<span
class="math inline">\(Var(\varepsilon_i|x_i)=\sigma_i^2=\sigma^2v_i\)</span></li>
<li>回归模型两边同时乘权重<span
class="math inline">\(\frac{1}{\sqrt{v_i}}\)</span>，新扰动项<span
class="math inline">\(\frac{\varepsilon_i}{\sqrt{v_i}}\)</span>不再有异方差</li>
<li>对回归模型进行OLS回归，最小化加权残差平方和<span
class="math inline">\(min\sum^n_{i=1}\limits(\frac{e_i}{\sqrt{v_i}})^2=\sum^n_{i=1}\limits\frac{e_i^2}{v_i}\)</span>，权重为方差的倒数<span
class="math inline">\(\frac{1}{v_i}\)</span></li>
</ol></li>
<li><p>FWLS：</p>
<ul>
<li>why FWLS：使用WLS虽可得到BLUE估计，但须知道每位个体的方差，但<span
class="math inline">\(\{\sigma^2_i\}^n_{i=1}\)</span>在实践中通常不知</li>
<li>思路：先用样本数据估计<span
class="math inline">\(\{\sigma^2_i\}^n_{i=1}\)</span>，再使用WLS</li>
<li>步骤：
<ol type="1">
<li>BP检验时进行辅助回归<span
class="math inline">\(e_i^2=\delta_1+\delta_2x_{i2}+...+\delta_Kx_{iK}+error_i\)</span></li>
<li>得到<span class="math inline">\(\sigma^2_i\)</span>的估计值<span
class="math inline">\(\hat{\sigma^2_i}=\hat{\delta_1}+\hat{\delta_2}x_{i2}+...+\hat{\delta_K}x_{iK}\)</span></li>
<li>为保证<span
class="math inline">\(\hat{\sigma^2_i}\)</span>始终为正，假设条件方差函数为对数形式：<span
class="math inline">\(ln(e_i^2)=\delta_1+\delta_2x_{i2}+...+\delta_Kx_{iK}+error_i\)</span>，对此方程进行OLS回归，得到<span
class="math inline">\(lne^2_i\)</span>的预测值<span
class="math inline">\(ln(\hat{\sigma_i^2})\)</span>，则<span
class="math inline">\(\hat{\sigma_i^2}=e^{ln\hat{\sigma^2_i}}\)</span>一定为正</li>
<li>以<span
class="math inline">\(\frac{1}{\hat{\sigma^2_i}}\)</span>为权重对原方程进行WLS估计</li>
</ol></li>
<li>优点：在大样本下比OLS更有效率</li>
<li>缺点：由于<span
class="math inline">\(\hat{\beta_{FWLS}}\)</span>是y的非线性函数，一般有偏，所以不是BLUE</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>exogenous外生性</p>
<ul>
<li><p>The <strong>residuals</strong> should be independent to
independent variables. 残差向量和每一个解释变量正交</p></li>
<li><p><span class="math inline">\(E(\varepsilon|X)=0\)</span>,
condition on X, the expectation of residual is 0.</p></li>
</ul></li>
</ol>
<h2 id="ols优良性质">OLS优良性质</h2>
<h3 id="blue">BLUE</h3>
<p>在经典假设下，OLS估计量估计量具有，线性、无偏性和有效性三个优良性质，称为最佳线性无偏估计量（best
linear unbiased estimator,BLUE）</p>
<p>球形扰动项下的估计量是最佳线性无偏估计量（BLUE），这个结论叫<strong>高斯马尔科夫定理</strong></p>
<h3 id="大样本">大样本</h3>
<ul>
<li>一致：<span class="math inline">\(\underset{n\rightarrow
\infty}{plim}\hat{\beta_n}=\beta\)</span></li>
<li>渐进正态Asymptotic normal distribution：<span
class="math inline">\(\hat{\beta_n}\xrightarrow{d} N(\beta,
\frac{\sigma^2}{n})\)</span></li>
</ul>
<h2 id="线性回归模型">线性回归模型</h2>
<p><span class="math display">\[
Y=X\beta+\varepsilon
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
L_\beta &amp;=(Y-X\beta)^\top (Y-X\beta)\\
&amp;=Y^\top Y-Y^\top X\beta-\beta^\top X^\top Y+\beta^\top X^\top
X\beta
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial L_\beta}{\partial \beta}&amp;=-X^\top Y-X^\top Y +X^\top
X\beta+(\beta^\top X^\top X)^\top\\
&amp;=-2X^\top Y+2X^\top X\beta\\
&amp;=2X^\top (X\beta - Y)\\
&amp;=0
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\hat{\beta}=(X^\top X)^{-1}X^\top Y
\]</span></p>
<h3 id="梯度下降法求解hatbeta">梯度下降法求解<span
class="math inline">\(\hat{\beta}\)</span></h3>
<p>梯度下降法损失函数用MSE： <span class="math display">\[
MSE(\beta)=\frac{1}{n}(Y-X\beta)^\top (Y-X\beta)
\]</span></p>
<p><span class="math display">\[
\nabla MSE(\beta)=\frac{2}{n}X^\top (X\beta - Y)
\]</span></p>
<p>梯度下降： <span class="math display">\[
\beta = \beta-\alpha\nabla MSE(\beta)
\]</span> 其中<span class="math inline">\(\alpha\)</span>是学习率</p>
<h4
id="梯度下降法损失函数用mse的原因">梯度下降法损失函数用MSE的原因</h4>
<p>在使用梯度下降法求解线性回归时，常用的损失函数是均方误差（MSE）而不是误差平方和（SSE）。</p>
<p>误差平方和（SSE）是指所有样本点的预测值与真实值之差的平方和，而均方误差（MSE）是指所有样本点的预测值与真实值之差的平方和除以样本数量。这两个指标在一定程度上是相关的，但在优化过程中，使用MSE可以更好地优化模型。</p>
<ul>
<li>MSE可以缓解样本数量的影响。SSE随着样本数量的增加而增加，而MSE则不会随样本数量变化而变化，这使得使用MSE更具有泛化性能。因此，当使用梯度下降算法优化模型时，使用MSE可以更好地应对不同大小的数据集，而不需要调整超参数</li>
</ul>
<p>综上所述，使用MSE作为损失函数可以更好地应对不同大小的数据集，并且可以使梯度下降算法更加高效</p>
<h3 id="期望和方差">期望和方差</h3>
<p><span class="math display">\[
\begin{aligned}
E[\hat{\beta}]&amp;=E[(X^\top X)^{-1}X^\top (X\beta+\varepsilon)]\\
&amp;=(X^\top X)^{-1}X^\top X\beta + (X^\top X)^{-1}X^\top
E[\varepsilon]\\
&amp;=\beta
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
Var(\hat{\beta})&amp;=E[(\hat{\beta}-E[\hat{\beta}])(\hat{\beta}-E[\hat{\beta}])]\\
&amp;=E[(\hat{\beta} -\beta)(\hat{\beta}-\beta)^\top]\\
                &amp;=E[\hat{\beta}\hat{\beta}^\top-\hat{\beta}
\beta^\top -\beta \hat{\beta}^\top +\beta \beta^\top]\\
                &amp;=E[\hat{\beta}\hat{\beta}^\top]-E[\hat{\beta}]\beta^\top-\beta
E[\hat{\beta}^\top]+\beta \beta^\top\\
                &amp;=E[(X^\top X)^{-1}X^\top YY^\top X((X^\top
X)^{-1})^\top]-\beta\beta^\top-\beta \beta^\top+\beta \beta^\top\\
                &amp;=(X^\top X)^{-1}X^\top E[YY^\top]X(X^\top
X)^{-1}-\beta\beta^\top\\
                &amp;=(X^\top X)^{-1}X^\top E[(X\beta +
\varepsilon)(X\beta + \varepsilon)^\top]X(X^\top
X)^{-1}-\beta\beta^\top\\
                &amp;=(X^\top X)^{-1}X^\top E[(X\beta +
\varepsilon)(\beta^\top X^\top + \varepsilon^\top)]X(X^\top
X)^{-1}-\beta\beta^\top\\
                &amp;=(X^\top X)^{-1}X^\top E[X\beta \beta^\top X^\top +
X\beta\varepsilon^\top+\varepsilon\beta^\top X^\top +\varepsilon
\varepsilon^\top]X(X^\top X)^{-1}-\beta\beta^\top\\
                &amp;=(X^\top X)^{-1}X^\top (X\beta \beta^\top X^\top +
\sigma^2 I_n )X(X^\top X)^{-1}-\beta\beta^\top\\
                &amp;=\beta\beta^\top +\sigma^2 (X^\top
X)^{-1}-\beta\beta^\top\\
                &amp;=\sigma^2 (X^\top X)^{-1}
\end{aligned}
\]</span></p>
<h3 id="损失函数用残差平方和的原因">损失函数用残差平方和的原因</h3>
<p>正态分布MLE是二次，所以损失函数不用更高次的和</p>
<h3 id="遗漏变量冗余变量与扰动项">遗漏变量、冗余变量与扰动项</h3>
<h4 id="遗漏变量">遗漏变量</h4>
<p><span class="math display">\[
\beta=
\left( \begin{array}{c}
    \beta_0\\
    \beta_1\\
    \beta_2\\
\end{array} \right)\\
X=(1,x_{1t},x_{2t})\\
r=X\beta+\varepsilon\\
\beta=(X^\top X)^{-1}X^\top r\\
\]</span></p>
<p>Denote <span class="math display">\[
X&#39;=(1,x_{1t})\\
\begin{aligned}
\beta&#39;=\left( \begin{array}{c}
    \hat{\alpha}\\
    \hat{\beta}\\
\end{array} \right)&amp;=(X&#39;^\top X&#39;)^{-1}X&#39;^\top r\\
&amp;=(X&#39;^\top X&#39;)^{-1}X&#39;^\top (X\beta+\varepsilon)\\
&amp;=(X&#39;^\top X&#39;)^{-1}X&#39;^\top X\beta+(X&#39;^\top
X&#39;)^{-1}X&#39;^\top \varepsilon\\
\end{aligned}
\]</span> Then <span class="math display">\[
E[\beta&#39;]=(X&#39;^\top X&#39;)^{-1}X&#39;^\top X\beta\\
\begin{aligned}
\left( \begin{array}{c}
    \hat{\alpha}\\
    E[\hat{\beta}]\\
\end{array} \right)&amp;=\left( \begin{array}{c}
    1&amp;x_{1t}\\
    x_{1t}&amp; x_{1t}x_{1t}^\top\\
\end{array} \right)^{-1}\left( \begin{array}{c}
    1&amp;x_{1t}&amp;x_{2t}\\
    x_{1t}&amp;x_{1t}x_{1t}^\top &amp;x_{1t}x_{2t}^\top
\end{array} \right)\left( \begin{array}{c}
    \beta_0\\
    \beta_1\\
    \beta_2\\
\end{array} \right)\\
&amp;=\left( \begin{array}{c}
    1&amp;0&amp;k_1\\
    0&amp;1&amp;k_2\\
\end{array} \right)\left( \begin{array}{c}
    \beta_0\\
    \beta_1\\
    \beta_2\\
\end{array} \right)
\end{aligned}
\]</span> <span class="math display">\[
E[\hat{\beta}]=\beta_1+\frac{Cov(x_1, x_2)}{Var(x_1)}\beta_2
\]</span> If <span class="math inline">\(k_2\ne0\)</span>, <span
class="math inline">\(\hat{\beta}\)</span> is not an unbiased estimator
of <span class="math inline">\(\beta_1\)</span> in (1), and it's not
consistent. The bias direction is based on <span
class="math inline">\(k_2\propto Cov(x_{1t},x_{2t})\)</span>.</p>
<p>由于遗漏变量<span
class="math inline">\(x_2\)</span>被归入扰动项中，可能增大扰动项的方差，影响OLS估计的精确度</p>
<h4 id="冗余变量">冗余变量</h4>
<p>Denote <span class="math display">\[
\begin{aligned}
X&#39;&amp;=(1,x_{1t},x_{2t},x_{3t})\\
&amp;=\left( \begin{matrix}
    1&amp;      x_{11}&amp;     x_{21}&amp;     x_{31}\\
    1&amp;      x_{12}&amp;     x_{22}&amp;     x_{32}\\
    ...&amp;        ...&amp;        ...&amp;        ...\\
    1&amp;      x_{1T}&amp;     x_{2T}&amp;     x_{3T}\\
\end{matrix} \right)
\end{aligned}
\]</span></p>
<p><span class="math display">\[
A=\left( \begin{matrix}
    1&amp;      0&amp;      0\\
    0&amp;      1&amp;      0\\
    0&amp;      0&amp;      1\\
    0&amp;      0&amp;      0\\
\end{matrix} \right)
\]</span></p>
<p>Then <span class="math display">\[
X=X&#39;A\\
\beta&#39;=\left( \begin{array}{c}
    \hat{\gamma}_0\\
    \hat{\gamma}_1\\
    \hat{\gamma}_2\\
    \hat{\gamma}_3
\end{array} \right)=(X&#39;^\top X&#39;)^{-1}X&#39;^\top
X&#39;A\beta+(X&#39;^\top X&#39;)^{-1}X&#39;^\top \varepsilon\\
E[\beta&#39;]=(X&#39;^\top X&#39;)^{-1}X&#39;^\top X&#39;A\beta=A\beta\\
\left( \begin{array}{c}
    E[\hat{\gamma}_0]\\
    E[\hat{\gamma}_1]\\
    E[\hat{\gamma}_2]\\
    E[\hat{\gamma}_3]
\end{array} \right)=\left( \begin{matrix}
    1&amp;      0&amp;      0\\
    0&amp;      1&amp;      0\\
    0&amp;      0&amp;      1\\
    0&amp;      0&amp;      0\\
\end{matrix} \right)\left( \begin{array}{c}
    \beta_0\\
    \beta_1\\
    \beta_2\\
\end{array} \right)=\left( \begin{array}{c}
    \beta_0\\
    \beta_1\\
    \beta_2\\
    0
\end{array} \right)
\]</span> That is <span class="math display">\[
E[\hat{\gamma}_1]=\beta_1\\
E[\hat{\gamma}_2]=\beta_2
\]</span> <span class="math inline">\(\hat{\gamma}_1\)</span> and <span
class="math inline">\(\hat{\gamma}_2\)</span> are unbiased estimators of
<span class="math inline">\(\beta_1\)</span> and <span
class="math inline">\(\beta_2\)</span> in (1). So they are
consistent.</p>
<p>影响：引入无关变量后，受到无关变量的干扰，估计量<span
class="math inline">\(\hat{\beta}\)</span>的方差一般会增大</p>
<h4 id="x有扰动项">X有扰动项</h4>
Denote $$ =(
<span class="math display">\[\begin{matrix}
    0&amp;      \delta_{11}&amp;        \delta_{21}\\
    0&amp;      \delta_{12}&amp;        \delta_{22}\\
    ...&amp;        ...&amp;        ...\\
    0&amp;      \delta_{1T}&amp;        \delta_{2T}\\
\end{matrix}\]</span>
)\ E[]=0\ X'=X+\
<span class="math display">\[\begin{aligned}
\beta&#39;=\left( \begin{array}{c}
    \hat{\beta}_0\\
    \hat{\beta}_1\\
    \hat{\beta}_2\\
\end{array} \right)&amp;=(X&#39;^\top X&#39;)^{-1}X&#39;^\top
(X&#39;-\varDelta)\beta+(X&#39;^\top X&#39;)^{-1}X&#39;^\top
\varepsilon\\
&amp;=(I-(X&#39;^\top
X&#39;)^{-1}X&#39;^\top\varDelta)\beta+(X&#39;^\top
X&#39;)^{-1}X&#39;^\top \varepsilon\\
&amp;=(I-([(X+\varDelta)^\top
(X+\varDelta)]^{-1}(X+\varDelta)^\top\varDelta)\beta\\
&amp;\quad+(X&#39;^\top X&#39;)^{-1}X&#39;^\top \varepsilon\\

\end{aligned}\]</span>
\ <span class="math display">\[
Then
\]</span>
<span class="math display">\[\begin{aligned}
E[\beta&#39;]&amp;=[I-E[X^\top X+X^\top\varDelta+\varDelta^\top
X+\varDelta^\top \varDelta)^{-1}(X^\top \varDelta+\varDelta^\top
\varDelta)]]\beta\\
&amp;\ne\beta
\end{aligned}\]</span>
<p><span class="math display">\[
Ms. Noisy cannot get unbiased estimators of $\beta_1$ and $\beta_2$ in
(1). Since
\]</span> E[X<sup>X+X</sup>+<sup>X+</sup>)<sup>{-1}(X</sup>+^)] $$ She
cannot get consistent estimators.</p>
<h2 id="评价指标">评价指标</h2>
<h3 id="r2"><span class="math inline">\(R^2\)</span></h3>
<h4 id="平方和分解公式-sum-of-squares-decomposition">平方和分解公式 Sum
of squares decomposition</h4>
<p>成立条件：</p>
<p><span class="math inline">\(\hat{y}\)</span>和<span
class="math inline">\(e\)</span>正交 <span class="math display">\[
\hat{y}^\top e=(X\hat{\beta})^\top e=\hat{\beta}^\top X^\top e=0
\]</span></p>
<p><span class="math display">\[
y=\hat{y}+e
\]</span></p>
<p>回归平方和：ESS (explained sum of squares)</p>
<p>残差平方和：RSS(residual sum of squares)</p>
<p>总离差平方和：TSS(total sum of squares)</p>
<p>ESS+RSS=TSS</p>
<p><span class="math display">\[
ESS=\sum^n_{i=1}(\hat{y_i}-\bar{y})^2
\]</span> <span class="math display">\[
RSS=\sum^n_{i=1}(\hat{y_i}-y_i)^2
\]</span> <span class="math display">\[
TSS=\sum^n_{i=1}(y_i-\bar{y})^2
\]</span></p>
<p><span class="math display">\[
R^2=\frac{ESS}{TSS}=1-\frac{RSS}{TSS}=\frac{Var(\hat{y})}{Var(y)}=1-\frac{MSE}{Var(y)}
\]</span></p>
<p><span class="math display">\[
TSS=ESS+RSS\\
\sum(y_i-\bar{y})^2=\sum (\hat{y}_i-\bar{y})^2+\sum e_i^2
\]</span></p>
<h4 id="r2-1"><span class="math inline">\(R^2\)</span></h4>
<p>R²是指拟合优度，是回归直线对观测值的拟合程度。</p>
<p>R-square is used to evaluate the goodness of fit of a linear
regression model. It is a value between 0 and 1 and itrepresents the
proportion of the variation in the dependent variable that is explained
by the independent variables in the model.</p>
<p>因变量的变化有多少比例可以由自变量解释</p>
<h4 id="r2的缺陷"><span class="math inline">\(R^2\)</span>的缺陷</h4>
<ul>
<li>对异常值敏感（平方项）</li>
<li>对自变量个数敏感（增加个数会增大<span
class="math inline">\(R^2\)</span>）</li>
<li>无法区分线性与非线性关系</li>
<li>无常数项时不用R²度量拟合优度（平方和分解公式不成立）</li>
</ul>
<h4 id="样本外r2为负数">样本外<span
class="math inline">\(R^2\)</span>为负数</h4>
<p>RSS&gt;TSS</p>
<h4 id="调整r2很多变量">调整<span
class="math inline">\(R^2\)</span>（很多变量）</h4>
<p>The adjusted R square takes into account the influence of sample size
and the number of independent variables in the regression.</p>
<p><span
class="math inline">\(R^2\)</span>问题：增加自变量的个数会使<span
class="math inline">\(R^2\)</span>增大</p>
<p>解决方法：调整<span class="math inline">\(R^2\)</span> <span
class="math display">\[
R_{adj}=1-\frac{\frac{RSS}{n-p-1}}{\frac{TSS}{n-1}}
\]</span> <span class="math inline">\(p\)</span>是自变量个数，<span
class="math inline">\(n\)</span>是样本数量</p>
<p>问题：可能为负</p>
<h4 id="uncentered-r2">uncentered <span
class="math inline">\(R^2\)</span></h4>
<p><span class="math display">\[
R^2_{uc}=\frac{\sum \hat{y_i}^2}{\sum y_i^2}
\]</span></p>
<p>来使<span class="math inline">\(R^2\)</span>在0到1之间</p>
<h3 id="t检验和f检验">t检验和F检验</h3>
<ul>
<li><p>t检验和F检验的关系：单个变量的t检验平方就是自由度为1的F检验（第一自由度为1，第二自由度为样本量）</p></li>
<li><p>F检验和R²的关系：R²是去掉所有解释变量，只保留常数项的F检验</p>
<p>对于线性回归方程<span
class="math inline">\(y_i=\beta_1+\beta_2x_{i2}+...+\beta_{K}x_{iK}+\varepsilon_i\)</span>，检验原假设<span
class="math inline">\(H_0:\beta_2=...=\beta_{K}=0\)</span>的F统计量等于<span
class="math inline">\(\frac{R^2/(K-1)}{(1-R^2)/(n-K)}\)</span></p>
<ul>
<li>R²并非决定F统计量的唯一因素，还取决于样本容量n与解释变量个数K</li>
</ul></li>
</ul>
<h2 id="xy数量变化的影响">X、Y数量变化的影响</h2>
<h3 id="hatbeta"><span class="math inline">\(\hat{\beta}\)</span></h3>
<p><span class="math display">\[
\hat{\beta}=(X^\top X)^{-1}X^\top Y
\]</span></p>
<p>Y→a倍：<span class="math inline">\(\hat{\beta}\)</span>→a倍</p>
<p>X→a倍：<span class="math inline">\(\hat{\beta}\)</span>→1/a倍</p>
<p>样本复制一倍： <span class="math display">\[
\left( \begin{matrix}
    \left( \begin{array}{c}
    X\\
    X\\
\end{array} \right)&amp;        \left( \begin{array}{c}
    Y\\
    Y\\
\end{array} \right)\\
\end{matrix} \right)
\]</span> 则 <span class="math display">\[
\begin{aligned}
\hat{\beta}&amp;=\left( \begin{matrix}
    \left( \begin{array}{c}
    X\\
    X\\
\end{array} \right) ^{\top}&amp;        \left( \begin{array}{c}
    X\\
    X\\
\end{array} \right)\\
\end{matrix} \right) ^{-1}\left( \begin{array}{c}
    X\\
    X\\
\end{array} \right) ^{\top}\left( \begin{array}{c}
    Y\\
    Y\\
\end{array} \right) \\
&amp;=\left( \begin{matrix}
    \left( \begin{matrix}
    X^{\top}&amp;       X^{\top}\\
\end{matrix} \right)&amp;       \left( \begin{array}{c}
    X\\
    X\\
\end{array} \right)\\
\end{matrix} \right) ^{-1}\left( \begin{matrix}
    X^{\top}&amp;       X^{\top}\\
\end{matrix} \right)\left( \begin{array}{c}
    Y\\
    Y\\
\end{array} \right)\\
&amp;=(2X^\top Y)^{-1}(2X^\top Y)\\
&amp;=(X^\top X)^{-1}X^\top Y
\end{aligned}
\]</span> 当样本复制一倍的时候，相当于<span
class="math inline">\(X\)</span>矩阵变为了<span
class="math inline">\(\left( \begin{array}{c}  X\\  X\\ \end{array}
\right)\)</span>，相应的<span class="math inline">\(X^\top
X\)</span>的值就变为原来的2倍。所以，在<span
class="math inline">\(\sigma^2\)</span>已知的情况下，<span
class="math inline">\(Var(\hat{\beta})=\sigma^2 (X^\top
X)^{-1}\)</span>变为原来的<span
class="math inline">\(\frac{1}{2}\)</span>。</p>
<h3 id="t检验值">t检验值</h3>
<p><span class="math display">\[
t=\frac{\hat{\beta}-\beta}{SE(\hat{\beta})}
\]</span></p>
<p>Y→a倍：t→不变</p>
<p>X→a倍：t→不变</p>
<p>样本复制一倍：t→<span class="math inline">\(\sqrt{2}\)</span>t</p>
<h3 id="r2-2"><span class="math inline">\(R^2\)</span></h3>
<p>Y→a倍：<span class="math inline">\(R^2\)</span>→不变</p>
<p>X→a倍：<span class="math inline">\(R^2\)</span>→不变</p>
<p>样本复制一倍：<span class="math inline">\(R^2\)</span>→不变【<span
class="math inline">\(\hat{\beta}\)</span>不变，预测值不变】</p>
<h2 id="线性回归准备">线性回归准备</h2>
<ol type="1">
<li><p>数据清洗和预处理：这涉及将数据从原始数据中提取出来，检查和处理数据中的缺失值、异常值和重复值。确保数据符合线性回归的前提假设。</p></li>
<li><p>可视化和描述性统计分析：通过图表和统计指标来理解数据的分布情况、变量之间的关系和异常值的存在。这些信息可以帮助确定应该使用哪种线性回归模型，以及哪些变量需要包含在模型中。</p></li>
<li><p>数据划分：将数据集划分为训练集和测试集，以便评估模型的性能并防止过度拟合。</p></li>
<li><p>特征工程：根据问题的要求，对数据进行特征工程，例如特征选择、特征变换和特征提取等，以便更好地表示数据和提高模型的性能。相关性分析</p></li>
<li><p>模型选择和训练：选择合适的线性回归模型，并对模型进行训练和调整参数，以便使模型在训练集上的性能最优。</p></li>
<li><p>Data cleaning and preprocessing: This involves extracting data
from raw data, checking and handling missing values, outliers, and
duplicates in the data. Ensure that the data meets the assumptions of
linear regression.</p></li>
<li><p>Visualization and descriptive statistical analysis: Understand
the distribution of data, the relationship between variables, and the
presence of outliers through charts and statistical indicators. This
information can help determine which linear regression model to use and
which variables to include in the model.</p></li>
<li><p>Data partitioning: Divide the data set into training and test
sets to evaluate model performance and prevent overfitting.</p></li>
<li><p>Feature engineering: Perform feature engineering on the data
according to the requirements of the problem, such as feature selection,
feature transformation, and feature extraction, to better represent the
data and improve the performance of the model. Analyze
correlation.</p></li>
<li><p>Model selection and training: Choose the appropriate linear
regression model and train and adjust the parameters of the model to
achieve optimal performance on the training set.</p></li>
</ol>
<p>数据分布对线性回归模型的影响主要表现在以下两个方面：</p>
<h2 id="线性回归数据分布的影响">线性回归数据分布的影响</h2>
<ol type="1">
<li><p>数据分布是否符合线性回归的基本假设</p>
<p>线性回归模型的基本假设是，自变量与因变量之间存在线性关系，且残差（实际值与预测值之间的差异）是独立同分布且服从正态分布的。如果数据分布不符合这些假设，那么线性回归模型的预测结果可能会受到影响。</p>
<p>例如，如果因变量的分布是偏态分布，那么线性回归模型可能会出现预测偏差，因为线性回归模型假设残差服从正态分布，而偏态分布的数据可能导致残差的非正态分布。同样，如果因变量与自变量之间的关系是非线性的，那么线性回归模型可能无法捕捉到这种关系，导致预测结果不准确。</p></li>
<li><p>数据分布的离群值和异常值</p>
<p>离群值和异常值可以对线性回归模型的预测结果产生很大的影响。因为线性回归模型是基于最小二乘法来求解的，它对离群值非常敏感，如果数据集中存在离群值，那么它们可能会对模型的系数估计和预测结果产生很大的影响。</p></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%95%B0%E5%AD%A6/" class="category-chain-item">数学</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%95%B0%E5%AD%A6/%E5%9B%9E%E5%BD%92/" class="category-chain-item">回归</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>线性回归</div>
      <div>http://example.com/2023/03/03/数学/线性回归/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>冰柠果儿</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年3月3日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/03/03/%E6%95%B0%E5%AD%A6/%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%92%8CLASSO%E5%9B%9E%E5%BD%92/" title="岭回归和LASSO回归">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">岭回归和LASSO回归</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/03/03/%E6%95%B0%E5%AD%A6/%E7%BB%9F%E8%AE%A1/" title="统计">
                        <span class="hidden-mobile">统计</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
