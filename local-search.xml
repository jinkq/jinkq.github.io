<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>面试</title>
    <link href="/2023/03/03/%E9%87%91%E8%9E%8D/%E9%9D%A2%E8%AF%95/"/>
    <url>/2023/03/03/%E9%87%91%E8%9E%8D/%E9%9D%A2%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h1 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h1><h2 id="experience-invest-in-stocks"><a href="#experience-invest-in-stocks" class="headerlink" title="experience invest in stocks"></a>experience invest in stocks</h2><h2 id="what-factor-you-find-is-most-efficent"><a href="#what-factor-you-find-is-most-efficent" class="headerlink" title="what factor you find is most efficent"></a>what factor you find is most efficent</h2><h2 id="experience-in-buying-individual-stock"><a href="#experience-in-buying-individual-stock" class="headerlink" title="experience in buying individual stock"></a>experience in buying individual stock</h2><h2 id="P-x2F-E-low-understanding-of-this-phenomenon-科技公司高，金融企业低（interest-rate-impact，sensitivity-is-different）"><a href="#P-x2F-E-low-understanding-of-this-phenomenon-科技公司高，金融企业低（interest-rate-impact，sensitivity-is-different）" class="headerlink" title="P&#x2F;E low, understanding of this phenomenon, 科技公司高，金融企业低（interest rate impact，sensitivity is different）"></a>P&#x2F;E low, understanding of this phenomenon, 科技公司高，金融企业低（interest rate impact，sensitivity is different）</h2><h2 id="股票和外汇risk-indicator"><a href="#股票和外汇risk-indicator" class="headerlink" title="股票和外汇risk indicator"></a>股票和外汇risk indicator</h2><h2 id="cta-risk-parity-in-equicy-currency-commodity-futures"><a href="#cta-risk-parity-in-equicy-currency-commodity-futures" class="headerlink" title="cta risk parity, in equicy, currency, commodity futures"></a>cta risk parity, in equicy, currency, commodity futures</h2><h2 id="multi-strategies"><a href="#multi-strategies" class="headerlink" title="multi strategies"></a>multi strategies</h2><h2 id="多资产配置叫股债混合型基金uture-period"><a href="#多资产配置叫股债混合型基金uture-period" class="headerlink" title="多资产配置叫股债混合型基金uture period."></a>多资产配置叫股债混合型基金uture period.</h2>]]></content>
    
    
    <categories>
      
      <category>金融</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>宏观</title>
    <link href="/2023/03/03/%E9%87%91%E8%9E%8D/%E5%AE%8F%E8%A7%82/"/>
    <url>/2023/03/03/%E9%87%91%E8%9E%8D/%E5%AE%8F%E8%A7%82/</url>
    
    <content type="html"><![CDATA[<h1 id="宏观"><a href="#宏观" class="headerlink" title="宏观"></a>宏观</h1><h2 id="结合当前宏观经济阐述下半年我国宏观经济走向以及资产配置建议"><a href="#结合当前宏观经济阐述下半年我国宏观经济走向以及资产配置建议" class="headerlink" title="结合当前宏观经济阐述下半年我国宏观经济走向以及资产配置建议"></a>结合当前宏观经济阐述下半年我国宏观经济走向以及资产配置建议</h2><h2 id="美联储是否加息，有什么影响"><a href="#美联储是否加息，有什么影响" class="headerlink" title="美联储是否加息，有什么影响"></a>美联储是否加息，有什么影响</h2><h2 id="经济政策和货币政策，三年内的例子，这两种政策怎么被用"><a href="#经济政策和货币政策，三年内的例子，这两种政策怎么被用" class="headerlink" title="经济政策和货币政策，三年内的例子，这两种政策怎么被用"></a>经济政策和货币政策，三年内的例子，这两种政策怎么被用</h2><h2 id="quantitative-easing-machanism"><a href="#quantitative-easing-machanism" class="headerlink" title="quantitative easing machanism"></a>quantitative easing machanism</h2><h2 id="currency-interest-rate-parity"><a href="#currency-interest-rate-parity" class="headerlink" title="currency interest rate parity"></a>currency interest rate parity</h2><h2 id="fundamental-driver-of-currency-change"><a href="#fundamental-driver-of-currency-change" class="headerlink" title="fundamental driver of currency change"></a>fundamental driver of currency change</h2>]]></content>
    
    
    <categories>
      
      <category>金融</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>量化</title>
    <link href="/2023/03/03/%E9%87%91%E8%9E%8D/%E9%87%8F%E5%8C%96/"/>
    <url>/2023/03/03/%E9%87%91%E8%9E%8D/%E9%87%8F%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="量化"><a href="#量化" class="headerlink" title="量化"></a>量化</h1><h2 id="量化交易都有哪些主要的策略类型"><a href="#量化交易都有哪些主要的策略类型" class="headerlink" title="量化交易都有哪些主要的策略类型"></a>量化交易都有哪些主要的策略类型</h2><p>Alpha 策略，CTA 策略以及高频交易策略</p>]]></content>
    
    
    <categories>
      
      <category>金融</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>衍生品</title>
    <link href="/2023/03/03/%E9%87%91%E8%9E%8D/%E8%A1%8D%E7%94%9F%E5%93%81/"/>
    <url>/2023/03/03/%E9%87%91%E8%9E%8D/%E8%A1%8D%E7%94%9F%E5%93%81/</url>
    
    <content type="html"><![CDATA[<h1 id="衍生品"><a href="#衍生品" class="headerlink" title="衍生品"></a>衍生品</h1><h2 id="期权、债券、互换、远期、期货等金融产品定价"><a href="#期权、债券、互换、远期、期货等金融产品定价" class="headerlink" title="期权、债券、互换、远期、期货等金融产品定价"></a>期权、债券、互换、远期、期货等金融产品定价</h2><h2 id="远期"><a href="#远期" class="headerlink" title="远期"></a>远期</h2><h3 id="从利率的期限结构来看，5-年即期利率为每年-10-，10-年即期利率为每年-15-。那么从第-5-年到第-10年的隐含远期收益率是多少？"><a href="#从利率的期限结构来看，5-年即期利率为每年-10-，10-年即期利率为每年-15-。那么从第-5-年到第-10年的隐含远期收益率是多少？" class="headerlink" title="从利率的期限结构来看，5 年即期利率为每年 10%，10 年即期利率为每年 15%。那么从第 5 年到第 10年的隐含远期收益率是多少？"></a>从利率的期限结构来看，5 年即期利率为每年 10%，10 年即期利率为每年 15%。那么从第 5 年到第 10年的隐含远期收益率是多少？</h3><p>设本金为$x$<br>$$<br>x\cdot(1+10%)^5(1+r)^5&#x3D;x\cdot(1+15%)^{10}<br>$$</p><h3 id="Cost-of-carry"><a href="#Cost-of-carry" class="headerlink" title="Cost of carry"></a>Cost of carry</h3><h2 id="给两个即期利率算远期利率"><a href="#给两个即期利率算远期利率" class="headerlink" title="给两个即期利率算远期利率"></a>给两个即期利率算远期利率</h2><h2 id="期货"><a href="#期货" class="headerlink" title="期货"></a>期货</h2><h3 id="远期和期货的区别"><a href="#远期和期货的区别" class="headerlink" title="远期和期货的区别"></a>远期和期货的区别</h3><h3 id="期货定价五个要素"><a href="#期货定价五个要素" class="headerlink" title="期货定价五个要素"></a>期货定价五个要素</h3><h2 id="期权"><a href="#期权" class="headerlink" title="期权"></a>期权</h2><h3 id="Vanilla-Option"><a href="#Vanilla-Option" class="headerlink" title="Vanilla Option"></a>Vanilla Option</h3><p>最基本的、标准化的欧式期权</p><h3 id="影响期权价格的因素"><a href="#影响期权价格的因素" class="headerlink" title="影响期权价格的因素"></a>影响期权价格的因素</h3><ul><li>price of underlying asset同一条件下，看涨期权价格与标的资产价格呈正比A is proportional to b，看跌期权与之呈反比A is inversely proportional to b。</li><li>strike price执行价格的高低对期权的影响与标的资产相反。</li><li>Price volatility of underlying asset同一条件下，波动率越高的期权价格越高。</li><li>Remaining time before due date同一条件下，有效期越长的期权价格越高。</li><li>risk-free rate期权价格与无风险利率呈反比</li><li>【optional】Income of underlying asset in holding period由于标的资产的分红付息等将降低标的资产的价格，而执行价格并未因此进行相应的调整，因此在期权有效期内，标的资产产生的红利将使看涨期权价格下降，而使看跌期权价格上升（Since the dividend of the underlying asset will decrease the price of the underlying asset, but the strike price has not been adjusted accordingly, the dividend generated by the underlying asset will decrease the price of call options and increase the price of put options during the effective period of the option）</li></ul><h3 id="假设标的资产近期将会出现大波动，市场有一个CALL和一个PUT可供选择，请构建出一个你觉得适合后市的期权套利组合，并画出对应的盈亏图"><a href="#假设标的资产近期将会出现大波动，市场有一个CALL和一个PUT可供选择，请构建出一个你觉得适合后市的期权套利组合，并画出对应的盈亏图" class="headerlink" title="假设标的资产近期将会出现大波动，市场有一个CALL和一个PUT可供选择，请构建出一个你觉得适合后市的期权套利组合，并画出对应的盈亏图"></a>假设标的资产近期将会出现大波动，市场有一个CALL和一个PUT可供选择，请构建出一个你觉得适合后市的期权套利组合，并画出对应的盈亏图</h3><h3 id="波动率"><a href="#波动率" class="headerlink" title="波动率"></a>波动率</h3><h4 id="波动率微笑"><a href="#波动率微笑" class="headerlink" title="波动率微笑"></a>波动率微笑</h4><p>波动率微笑（volatility smile）是指在金融市场上，不同执行价格的期权隐含波动率呈现出不同的形态，通常表现为执行价格远离标的资产现价的期权隐含波动率较高，而执行价格接近标的资产现价的期权隐含波动率较低，呈现出一个微笑的形态。</p><p>波动率微笑是由市场上期权买卖双方对未来市场波动性的不同预期所导致的。在市场中，投资者通常会根据其对未来市场波动性的预期来决定是否购买期权。当投资者预期市场波动性较高时，他们更倾向于购买执行价格远离标的资产现价的期权，以获得更高的潜在收益。因此，这些期权的价格会被市场推高，而其隐含波动率也会较高。相反，当投资者预期市场波动性较低时，他们更倾向于购买执行价格接近标的资产现价的期权，以保证稳定的收益，这些期权的价格则会被市场推低，而其隐含波动率也会较低。</p><p>For options with the same maturity date and underlying assets but different strike prices, the farther the strike price deviates from the spot price of the underlying assets, the greater the implied volatility. In the empirical study, the implied volatility calculated by the traditional BS option pricing model presents a phenomenon called “volatility smile”</p><h4 id="Volatility-skew"><a href="#Volatility-skew" class="headerlink" title="Volatility skew"></a>Volatility skew</h4><p>波动率偏斜（Volatility skew）指的是相同到期日、相同标的资产、相同执行价格的期权，但不同行权价的隐含波动率不同的现象。</p><p>通常情况下，波动率偏斜表现为，执行价格较低的看涨期权的隐含波动率高于执行价格较高的看涨期权的隐含波动率，而执行价格较高的看跌期权的隐含波动率高于执行价格较低的看跌期权的隐含波动率。这是由于投资者对市场上涨的担忧要大于对市场下跌的担忧，因此对于执行价格较低的看涨期权的需求较高，其价格也会相应地被推高，进而导致隐含波动率的上升；相反，对于执行价格较高的看涨期权的需求较低，其价格也会相应地被推低，进而导致隐含波动率的下降。</p><p>波动率偏斜在金融市场中比较常见，特别是在股票市场和外汇市场中。</p><h3 id="BS模型"><a href="#BS模型" class="headerlink" title="BS模型"></a>BS模型</h3><p>布朗运动是一种最简单的连续随机过程，它是描述证券价格随机性的基本模型。而对于期权或其他衍生品这些金融工具，它们的价格是相关证券资产价格的函数。因此可以说<strong>证券价格是一个随机过程，而衍生品价格是该随机过程的函数。伊藤引理提供了对随机过程的函数做微分的框架；这对于衍生品的定价意义非凡</strong>（在此之前，人们是不知道如何对随机过程的函数做微分的）。<strong>通过伊藤引理，可以写出金融衍生品价格的随机微分方程，通过对其求解便可以得到衍生品价格的模型。</strong>BS 公式就是一个最简单的例子。（BS 模型是一个偏微分方程，而 BS 公式是一个解析形式的表达式）</p><h4 id="BS模型假设"><a href="#BS模型假设" class="headerlink" title="BS模型假设"></a>BS模型假设</h4><p>Black-Scholes 期权的价格模型是建立在严格的假设基础上的，包<br>括以下几点：</p><ol><li>期权的标的资产的价格服从几何布朗运动，因此标的资产收<br>益率必须服从对数正态分布。The price of the underlying asset follows geometric Brownian motion, so the return of underlying asset<br>follows the lognormal distribution.</li><li>市场没有摩擦，没有税收和交易成本，没有卖空限制。There is no friction in the market, no tax and transaction costs, and no short position restrictions.</li><li>无风险利率不变。</li><li>期权不能在到期日之前行使，必须是欧式期权expiration date</li></ol><h4 id="为什么black-scholes方程（注意不是bs模型）中一阶项前面是无风险利率r，而不是风险利率（或者历史回报率）u？"><a href="#为什么black-scholes方程（注意不是bs模型）中一阶项前面是无风险利率r，而不是风险利率（或者历史回报率）u？" class="headerlink" title="为什么black scholes方程（注意不是bs模型）中一阶项前面是无风险利率r，而不是风险利率（或者历史回报率）u？"></a>为什么black scholes方程（注意不是bs模型）中一阶项前面是无风险利率r，而不是风险利率（或者历史回报率）u？</h4><p>风险中性定价，u经过测度变换可以得到r</p><p>融资成本所对应的回报率是r，而不是u</p><h4 id="布朗运动"><a href="#布朗运动" class="headerlink" title="布朗运动"></a>布朗运动</h4><p><strong>布朗运动是一个连续随机过程。一个随机过程是定义在时域或者空间域上的依次发生的一系列随机变量的集合。</strong>以时域为例，如果这些随机变量在整个实数时域上都有定义，那么这个随机过程为连续随机过程；反之，如果这些随机变量仅仅在时域上一些离散的点有定义，那么该随机过程为离散随机过程</p><h4 id="风险中性下推导-B-S-公式"><a href="#风险中性下推导-B-S-公式" class="headerlink" title="风险中性下推导 B-S 公式"></a>风险中性下推导 B-S 公式</h4><h4 id="BS公式和BS模型的区别"><a href="#BS公式和BS模型的区别" class="headerlink" title="BS公式和BS模型的区别"></a>BS公式和BS模型的区别</h4><p>BS公式和BS模型的公式基本相同，但是BS模型比BS公式更为复杂，包括了更多的变量和参数。</p><p>下面是BS公式和BS模型的公式：</p><p>BS公式：</p><p>$$C&#x3D;S_tN(d_1)-Ke^{-r(T-t)}N(d_2)$$</p><p>其中，$C$是欧式看涨期权的价格，$S_t$是标的资产的当前价格，$K$是期权的行权价格，$r$是无风险利率，$T-t$是期权到期时间，$N$是标准正态分布的累积分布函数，$d_1$和$d_2$分别为：</p><p>$$d_1&#x3D;\frac{\ln\left(\frac{S_t}{K}\right)+(r+\frac{1}{2}\sigma^2)(T-t)}{\sigma\sqrt{T-t}}$$</p><p>$$d_2&#x3D;d_1-\sigma\sqrt{T-t}$$</p><p>BS模型：</p><p>$$C&#x3D;S_tN(d_1)-Ke^{-r(T-t)}N(d_2)$$</p><p>其中，$C$、$S_t$、$K$、$r$、$T-t$、$N$、$d_1$和$d_2$的含义与BS公式相同，但是BS模型还考虑了标的资产的随机漂移和股息率等因素，因此$d_1$和$d_2$的计算方式略有不同：</p><p>$$d_1&#x3D;\frac{\ln\left(\frac{S_t}{K}\right)+(r+\frac{1}{2}\sigma^2)(T-t)}{\sigma\sqrt{T-t}}+ \frac{b}{\sigma}\sqrt{T-t}$$</p><p>$$d_2&#x3D;d_1-\sigma\sqrt{T-t}$$</p><p>其中，$b$是标的资产的随机漂移率，也称为股息率。可以看出，BS模型在计算$d_1$时多了一个$\frac{b}{\sigma}\sqrt{T-t}$的项。</p><h4 id="optimal-hedge-ratio"><a href="#optimal-hedge-ratio" class="headerlink" title="optimal hedge ratio"></a>optimal hedge ratio</h4><p>最优对冲比率（Optimal hedge ratio）是指在进行期货或期权交易时，用来确定期权头寸与期货头寸之间最佳的数量关系，以达到最小化投资组合风险的比率。</p><p>最优对冲比率是在现实市场情况下计算得出的，通常是通过回归分析等统计方法来确定。该比率表明了在给定期权头寸的情况下，需要持有多少头寸的期货合约才能实现最小化风险的效果。一般来说，最优对冲比率取决于期权的到期日、执行价格、标的资产价格波动率以及市场的流动性等因素。</p><p>最优对冲比率的计算对于期权和期货交易者来说都非常重要。对于期权交易者来说，最优对冲比率可以帮助他们在持有期权的同时，通过期货合约对价格波动的风险进行对冲，从而减小投资组合的风险；对于期货交易者来说，最优对冲比率可以帮助他们确定多空头寸之间的最佳数量关系，以达到最小化风险的效果</p><h5 id="期货最优对冲比率的计算"><a href="#期货最优对冲比率的计算" class="headerlink" title="期货最优对冲比率的计算"></a>期货最优对冲比率的计算</h5><p>期货最优对冲比率是指在持有期货合约的同时，持有多少的标的资产才能实现最小化风险的效果。最优对冲比率的计算需要使用线性回归方法，即将标的资产价格的变动作为自变量，将期货合约价格的变动作为因变量，通过回归分析来确定最优对冲比率。</p><p>具体而言，计算过程如下：</p><ol><li>收集一段时间内标的资产和期货合约的价格数据。</li><li>将标的资产价格的变动作为自变量，将期货合约价格的变动作为因变量，进行线性回归分析。</li><li>计算回归系数，即标的资产价格变动对期货合约价格变动的敏感度，得到最优对冲比率。</li></ol><p>例如，假设投资者持有原油期货合约，并且持有1000桶原油的现货头寸。通过分析历史数据，计算出最优对冲比率为0.8。则投资者需要持有800桶原油的现货头寸，才能实现最小化风险的效果。</p><h5 id="期权最优对冲比率的计算"><a href="#期权最优对冲比率的计算" class="headerlink" title="期权最优对冲比率的计算"></a>期权最优对冲比率的计算</h5><p>期权最优对冲比率是指在持有期权的同时，持有多少的标的资产才能实现最小化风险的效果。最优对冲比率的计算需要使用风险中性定价方法，即将标的资产价格的变动作为风险因素，通过期权的定价公式来计算最优对冲比率。</p><p>具体而言，计算过程如下：</p><ol><li>确定期权的到期日、执行价格和类型，以及标的资产的价格和波动率等参数。</li><li>根据期权的定价公式，计算出期权的理论价格。</li><li>通过偏导数公式计算期权价格对标的资产价格的敏感度，即Delta值。</li><li>计算最优对冲比率，即期权持有人需要持有多少的标的资产才能实现最小化风险的效果，即最优对冲比率等于Delta值除以标的资产价格的变动量。</li></ol><p>例如，假设投资者持有某只股票的看涨期权，执行价格为100元，到期日为三个月后，标的资产价格为110元，波动率为20%。通过期权定价公式计算出期权价格为6元。偏导数公式计算出Delta值为0.65。则最优对冲比率为0.65&#x2F;10&#x3D;0.065，即投资者需要持有15.38股标的资产，才能实现最小化风险的效果。</p><h4 id="Martingale基础知识"><a href="#Martingale基础知识" class="headerlink" title="Martingale基础知识"></a>Martingale基础知识</h4><p>在概率论和数学金融中，Martingale是一种随机过程，通常用于描述一个随机变量序列的演变。Martingale序列的一个重要特点是其在未来的预期值等于当前的值。这个性质被称为“无偏增长”或者“无记忆性”。</p><p>换句话说，如果一系列随机变量X1, X2, …, Xt是Martingale序列，那么在给定任何t时刻，我们可以预期Xt的未来值与当前的值相等。这个特性可以表示为：</p><p>E(Xt+1 | X1, X2, …, Xt) &#x3D; Xt</p><p>其中，E表示期望值。这个等式意味着，假设我们已经知道了当前时刻的随机变量值，那么下一时刻的期望值就等于当前的值。</p><p>Martingale序列通常用于研究随机过程的特性和性质，例如在金融领域，Martingale序列可以被用来描述股票价格的随机变化。如果一支股票价格的随机漂移是一个Martingale序列，那么其价格的期望值在任何时刻都应该等于当前价格，即股票价格不存在趋势或者偏差，是随机游走的。</p><p>在数学金融中，Martingale序列也可以用于衡量金融衍生品的价格。如果一个金融衍生品的价格符合Martingale序列的性质，那么在风险中性世界中，该衍生品的价格应该等于其期望收益的贴现值，即其价格应该等于其未来收益的期望值。这个性质被称为“风险中性定价法”，是金融衍生品定价的基本原理之一。</p><h3 id="期权价格-amp-期权价值"><a href="#期权价格-amp-期权价值" class="headerlink" title="期权价格 &amp; 期权价值"></a>期权价格 &amp; 期权价值</h3><p>期权价格和期权价值的关系是：期权价格等于期权内在价值和时间价值的总和，也就是期权价值。如果期权内在价值为负，那么期权的价格就等于时间价值。如果期权内在价值为正，那么期权的价格就等于内在价值加上时间价值。</p><h3 id="各种option-strategy"><a href="#各种option-strategy" class="headerlink" title="各种option strategy"></a>各种option strategy</h3><h4 id="Brownian-Motion"><a href="#Brownian-Motion" class="headerlink" title="Brownian Motion"></a>Brownian Motion</h4><ul><li>Ito Lemma</li><li>判断组合是不是marting’</li></ul><h4 id="BS-Formula公式和基本假设"><a href="#BS-Formula公式和基本假设" class="headerlink" title="BS Formula公式和基本假设"></a>BS Formula公式和基本假设</h4><h4 id="BS-Merton-Formula推导"><a href="#BS-Merton-Formula推导" class="headerlink" title="BS Merton Formula推导"></a>BS Merton Formula推导</h4><p>两种推导，一种是replication，一种是option+stock组合成risk-free portfolio（后者更被preferred）</p><h3 id="Put-Call-Parity"><a href="#Put-Call-Parity" class="headerlink" title="Put-Call Parity"></a>Put-Call Parity</h3><p>可以用来解释call由put，time value和intrisic value构成</p><h2 id="Binomial-Model"><a href="#Binomial-Model" class="headerlink" title="Binomial Model"></a>Binomial Model</h2><p>$c&#x3D;\pi_uc_u+\pi_dc_d$</p><h3 id="Realized-vol和im-vol"><a href="#Realized-vol和im-vol" class="headerlink" title="Realized vol和im vol"></a>Realized vol和im vol</h3><ul><li>各自的定义</li><li>两者的区别</li></ul><p>实现波动率（Realized Volatility）和隐含波动率（Implied Volatility）是衡量金融市场波动性的两个重要指标，二者的区别如下：</p><ol><li>实现波动率是根据历史数据计算的波动率，是过去某一段时间内实际价格的波动程度的测度。而隐含波动率是根据市场上对期权价格的交易计算得到的，是市场对未来波动率的预期的测度。</li><li>实现波动率是基于历史数据计算的，其计算方法可以有多种，比如对数收益率、价格变动率等。而隐含波动率是根据期权的市场价格和其他参数，使用期权定价模型计算得到的。</li><li>实现波动率是已知的，因为历史价格已经发生了，而隐含波动率是未知的，因为它是根据市场价格反推出来的。</li><li>实现波动率反映了市场实际的波动程度，而隐含波动率反映了市场对未来波动率的预期。实现波动率可以帮助投资者评估风险，而隐含波动率可以帮助投资者评估期权价格的合理性以及市场对未来波动率的看法。</li><li>实现波动率通常用于构建波动率交易策略，而隐含波动率通常用于期权定价和风险管理。</li></ol><h3 id="im-vol-surface特点"><a href="#im-vol-surface特点" class="headerlink" title="im vol surface特点"></a>im vol surface特点</h3><h3 id="Local-Vol模型"><a href="#Local-Vol模型" class="headerlink" title="Local Vol模型"></a>Local Vol模型</h3><ul><li>由Dupire拟合</li><li>Pros &amp; cons，还问过和原来BS Model的区别</li></ul><h3 id="Heston-Model"><a href="#Heston-Model" class="headerlink" title="Heston Model"></a>Heston Model</h3><h3 id="Dynamic-hedge-amp-static-hedge"><a href="#Dynamic-hedge-amp-static-hedge" class="headerlink" title="Dynamic hedge &amp; static hedge"></a>Dynamic hedge &amp; static hedge</h3><h3 id="奇异期权"><a href="#奇异期权" class="headerlink" title="奇异期权"></a>奇异期权</h3><h4 id="亚式期权的定价"><a href="#亚式期权的定价" class="headerlink" title="亚式期权的定价"></a>亚式期权的定价</h4><ul><li>Rainbow<ul><li>Corr &amp; option price的关系</li><li>Snowball</li><li>Accumulator</li></ul></li></ul><h3 id="Greek"><a href="#Greek" class="headerlink" title="Greek"></a>Greek</h3><table><thead><tr><th>Greek</th><th>Call</th><th>Put</th></tr></thead><tbody><tr><td>Delta($\frac{\partial}{\partial S_t}$)</td><td>$\phi(d_1)$</td><td>$-\phi(-d_1)$</td></tr><tr><td>Gamma($\frac{\partial^2}{\partial S_t^2}$)</td><td>$\frac{\phi(d_1)}{S_t\sigma\sqrt{\tau}}&#x3D;Ke^{-r\tau}\frac{\phi(d_2)}{S_t^2\sigma\sqrt{\tau}}$</td><td>同Call</td></tr><tr><td>Vega($\frac{\partial}{\partial \sigma}$)</td><td>$S_t\tau\psi(d_1)&#x3D;Ke^{-r\tau}\sqrt{\tau}\phi(d_2)$</td><td>同Call</td></tr><tr><td>Theta($\frac{\partial}{\partial t}$)</td><td>$-Ke^{-r\tau}\phi(d_2)-\frac{S_t\phi(d_1)\sigma}{2\sqrt{\tau}}$</td><td>$Ke^{-r\tau}\phi(-d_2)-\frac{S_t\phi(d_1)\sigma}{2\sqrt{\tau}}$</td></tr><tr><td>Rho($\frac{\partial}{\partial r}$)</td><td>$K\tau e^{-r\tau}\phi(d_2)$</td><td>$-K\tau e^{-r\tau}\phi(-d_2)$</td></tr></tbody></table><p>delta：call option为正，put option为负</p><p>gamma：多头一定为正</p><p>vega：多头为正，空头为负</p><h4 id="高阶Greek-formula"><a href="#高阶Greek-formula" class="headerlink" title="高阶Greek formula"></a>高阶Greek formula</h4><h5 id="Vanna"><a href="#Vanna" class="headerlink" title="Vanna"></a>Vanna</h5><p>$$<br>Vanna&#x3D;\frac{\partial^2 V}{\partial S \partial \sigma}&#x3D;\frac{\partial \varDelta}{\partial \sigma}<br>$$</p><p>Vanna衡量的是标的资产价格和波动率之间的敏感度，也就是当标的资产价格和波动率同时变化时，期权价格的变化量。</p><h5 id="Vomma"><a href="#Vomma" class="headerlink" title="Vomma"></a>Vomma</h5><p>$$<br>Vomma&#x3D;\frac{\partial^2 V}{\partial \sigma^2}&#x3D;\frac{\partial Vega}{\partial \sigma}<br>$$</p><p>Vomma衡量的是波动率对期权价格的敏感度，也就是当波动率变化时，期权价格的变化量。Vomma的具体定义是，对于一个持有期权头寸的投资者，当波动率变动一个单位时，Vega值的变化量。如果Vomma值为正，那么当波动率上涨时，期权价格也会上涨，反之则会下跌。</p><h4 id="Greek-formula的问题"><a href="#Greek-formula的问题" class="headerlink" title="Greek formula的问题"></a>Greek formula的问题</h4><ul><li>ITM&#x2F;ATM&#x2F;OTM delta的数值<ul><li>ITM期权的Delta数值为正数，接近于1；</li><li>ATM期权的Delta数值接近于0，可能略有正数或负数；</li><li>OTM期权的Delta数值为负数，接近于0。</li></ul></li><li>ATM delta略大于0.5的原因</li><li>类似call&#x2F;put的Gamma，Vega公式的区别</li><li>delta of at the money call option</li></ul><h4 id="Hedge"><a href="#Hedge" class="headerlink" title="Hedge"></a>Hedge</h4><p>delta hedge和gamma hedge risk</p><p>一个银行卖出100 put option, strike price 3700， 算怎么delta hedge</p><h4 id="Greek扩展问题"><a href="#Greek扩展问题" class="headerlink" title="Greek扩展问题"></a>Greek扩展问题</h4><p>做空call各类greek的方向</p><p>delta的衍生含义，e.g. ITM probability, binary option price</p><p>gamma的衍生含义</p><p>gamma和vega的区别</p><p>各类greek关于T, K, S变化的关系</p><p>e.g. ATM处，T越小，gamma越大</p><p>gamma&#x2F;vega关系，gamma&#x2F;theta关系</p><h5 id="各种greek之间可能的互相作用"><a href="#各种greek之间可能的互相作用" class="headerlink" title="各种greek之间可能的互相作用"></a>各种greek之间可能的互相作用</h5><p>各种Greek值代表了期权价格对不同因素的敏感程度，它们之间可能存在互相作用的关系，如下所示：</p><ol><li>Delta和Gamma：Delta值表示期权价格对标的资产价格变化的敏感程度，Gamma值则表示Delta值对标的资产价格变化的敏感程度。当Gamma值较高时，Delta值可能会剧烈变化，因此Delta和Gamma值之间存在密切关系。</li><li>Delta和Theta：Delta值对时间的敏感程度较低，而Theta值则表示期权价格随时间流逝而减少的速度。当期权到期时间越来越近时，Delta值可能会变化，因此Delta和Theta值之间也存在一定的关系。</li><li>Vega和Theta：Vega值表示期权价格对波动率变化的敏感程度，而Theta值则表示期权价格随时间流逝而减少的速度。当随着时间的推移，波动率逐渐减小，Vega值可能会下降，从而影响到Theta值的变化。</li><li>Vega和Gamma：Vega值也表示期权价格对波动率变化的敏感程度，而Gamma值则表示Delta值对标的资产价格变化的敏感程度。当波动率变化时，Gamma值可能会发生变化，进而影响到Delta值和期权价格的变化。</li></ol><h5 id="人们怎么用Greek，为什么重要"><a href="#人们怎么用Greek，为什么重要" class="headerlink" title="人们怎么用Greek，为什么重要"></a>人们怎么用Greek，为什么重要</h5><p>人们可以通过Greek值来评估期权价格和标的资产价格变化、波动率变化以及时间流逝对期权价格的影响程度，从而更好地进行风险管理和投资决策。</p><p>以下是Greek值的具体用途：</p><ol><li>Delta值：Delta值可以帮助投资者确定期权价格对标的资产价格变化的敏感程度。投资者可以通过调整Delta值，来进行动态对冲和风险管理。</li><li>Gamma值：Gamma值表示Delta值对标的资产价格变化的敏感程度。投资者可以利用Gamma值来调整Delta值，以便更好地进行风险管理。</li><li>Vega值：Vega值表示期权价格对波动率变化的敏感程度。投资者可以通过调整Vega值，来控制风险敞口和波动率风险。</li><li>Theta值：Theta值表示期权价格随时间流逝而减少的速度。投资者可以利用Theta值来管理时间价值和期权到期日的风险。</li></ol><p>Greek值在风险管理和投资决策中具有重要作用，能够帮助投资者更好地控制风险和获得收益。</p><h4 id="greek在不同strategy上的表现"><a href="#greek在不同strategy上的表现" class="headerlink" title="greek在不同strategy上的表现"></a>greek在不同strategy上的表现</h4><p>Greek值在不同策略上的表现会有所不同。以下是一些常见的期权交易策略以及它们与Greek值之间的关系：</p><ol><li>Delta中性策略：Delta中性策略旨在通过对冲Delta风险来获得收益。这些策略通常涉及同时买入或卖出期权和标的资产，并根据标的资产价格的变化调整Delta值。在这种情况下，Delta值是策略中最重要的Greek值之一。</li><li>Gamma scalping策略：Gamma scalping策略旨在通过利用Gamma值来获得收益。这些策略通常涉及买入或卖出期权，以利用Gamma值的增加或减少，同时对冲Delta风险。在这种情况下，Gamma值是策略中最重要的Greek值之一。</li><li>Vega交易策略：Vega交易策略旨在通过利用波动率的变化来获得收益。这些策略通常涉及买入或卖出期权，以利用Vega值的增加或减少。在这种情况下，Vega值是策略中最重要的Greek值之一。</li><li>时间价值策略：时间价值策略旨在通过利用时间价值的变化来获得收益。这些策略通常涉及买入或卖出期权，以利用Theta值的增加或减少。在这种情况下，Theta值是策略中最重要的Greek值之一。</li></ol><p>总之，每种策略对Greek值的依赖程度是不同的，因此在选择策略时需要考虑Greek值。同时，需要注意的是，不同Greek值之间的交互作用也可能影响策略的表现。</p><ul><li>long gamma long theta, long gamma short vega</li></ul><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20220912105717.png"></p><h4 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h4><h5 id="delta和underlying-price，用vanilla-call-example"><a href="#delta和underlying-price，用vanilla-call-example" class="headerlink" title="delta和underlying price，用vanilla call example"></a>delta和underlying price，用vanilla call example</h5><h5 id="什么情况下希望sell-the-gamma，用什么option-structure：short-a-call-and-put-at-the-same-time"><a href="#什么情况下希望sell-the-gamma，用什么option-structure：short-a-call-and-put-at-the-same-time" class="headerlink" title="什么情况下希望sell the gamma，用什么option structure：short a call and put at the same time"></a>什么情况下希望sell the gamma，用什么option structure：short a call and put at the same time</h5><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20220912111629.png"></p><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20220912113154.png"></p><h2 id="互换"><a href="#互换" class="headerlink" title="互换"></a>互换</h2><h3 id="利率互换"><a href="#利率互换" class="headerlink" title="利率互换"></a>利率互换</h3><h3 id="如果买了国债，怎么用swap来hedge"><a href="#如果买了国债，怎么用swap来hedge" class="headerlink" title="如果买了国债，怎么用swap来hedge"></a>如果买了国债，怎么用swap来hedge</h3>]]></content>
    
    
    <categories>
      
      <category>金融</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>固收</title>
    <link href="/2023/03/03/%E9%87%91%E8%9E%8D/%E5%9B%BA%E6%94%B6/"/>
    <url>/2023/03/03/%E9%87%91%E8%9E%8D/%E5%9B%BA%E6%94%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="固收"><a href="#固收" class="headerlink" title="固收"></a>固收</h1><h2 id="给出每期的现金流和即期利率，求出债券价格和久期"><a href="#给出每期的现金流和即期利率，求出债券价格和久期" class="headerlink" title="给出每期的现金流和即期利率，求出债券价格和久期"></a>给出每期的现金流和即期利率，求出债券价格和久期</h2><h2 id="债券的“yield”和“rate-of-return”的区别"><a href="#债券的“yield”和“rate-of-return”的区别" class="headerlink" title="债券的“yield”和“rate of return”的区别"></a>债券的“yield”和“rate of return”的区别</h2><p>债券的“yield”是“internal rate of return”或“yield-to-maturity”或“promised- yield”。如果你持有债券到期，那就是你的收入。</p><p>债券的“rate of return”是已实现现金流的内部收益率对持有者，如果债券在到期日之前出售，（已实现的）“rate of return”可以为正，可以为负。</p><p>假设你购买了一份promised 5%的债券如果你卖掉该债券，你的资本将受损失并且得到一个负的“rate of return”。然而，如果你持有债券直至到期，你将会得到promised 5%</p><h2 id="怎么measure-fix-income-product-bond-interest-rate-swap"><a href="#怎么measure-fix-income-product-bond-interest-rate-swap" class="headerlink" title="怎么measure fix income product(bond, interest rate swap)"></a>怎么measure fix income product(bond, interest rate swap)</h2><h2 id="carry-of-a-bond-coupun-financing-rate"><a href="#carry-of-a-bond-coupun-financing-rate" class="headerlink" title="carry of a bond(coupun - financing rate)"></a>carry of a bond(coupun - financing rate)</h2><h2 id="rho-of-a-bond-yield-curve"><a href="#rho-of-a-bond-yield-curve" class="headerlink" title="rho of a bond(yield curve)"></a>rho of a bond(yield curve)</h2><h2 id="diff-between-stock-bond-and-credit-bond"><a href="#diff-between-stock-bond-and-credit-bond" class="headerlink" title="diff between stock bond and credit bond"></a>diff between stock bond and credit bond</h2><h2 id="micro-driver-of-bond-privacy"><a href="#micro-driver-of-bond-privacy" class="headerlink" title="micro driver of bond privacy"></a>micro driver of bond privacy</h2><h2 id="inflation-data-soran-bond"><a href="#inflation-data-soran-bond" class="headerlink" title="inflation data soran bond"></a>inflation data soran bond</h2><h2 id="国债市场基本面"><a href="#国债市场基本面" class="headerlink" title="国债市场基本面"></a>国债市场基本面</h2>]]></content>
    
    
    <categories>
      
      <category>金融</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>定量计算</title>
    <link href="/2023/03/03/%E9%87%91%E8%9E%8D/%E5%AE%9A%E9%87%8F%E8%AE%A1%E7%AE%97/"/>
    <url>/2023/03/03/%E9%87%91%E8%9E%8D/%E5%AE%9A%E9%87%8F%E8%AE%A1%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<h1 id="定量计算"><a href="#定量计算" class="headerlink" title="定量计算"></a>定量计算</h1><h2 id="如果一只股票每年连续复利收益率的标准差是10-，那么连续复利4年股票收益率的标准差是多少"><a href="#如果一只股票每年连续复利收益率的标准差是10-，那么连续复利4年股票收益率的标准差是多少" class="headerlink" title="如果一只股票每年连续复利收益率的标准差是10%，那么连续复利4年股票收益率的标准差是多少"></a>如果一只股票每年连续复利收益率的标准差是10%，那么连续复利4年股票收益率的标准差是多少</h2><p>假设连续复利收益率遵循布朗运动算法，收益的方差与复利计算期呈线性增长。这是因为随机游走中的连续回报是有限的。而独立随机变量喝的方差的和就是方差的和。这意味着4年的 σ2 等于1年 σ2 的4倍。因此，4年的 σ 是1年 σ 的2倍，因此，答案就是20%。</p><h2 id="2-stock-expected-10-vol-is-10-corr-is-16-construct-portfolio-to-achieve-min-variance"><a href="#2-stock-expected-10-vol-is-10-corr-is-16-construct-portfolio-to-achieve-min-variance" class="headerlink" title="2 stock expected 10%, vol is 10%, corr is 16%, construct portfolio to achieve min variance"></a>2 stock expected 10%, vol is 10%, corr is 16%, construct portfolio to achieve min variance</h2><h2 id="VaR"><a href="#VaR" class="headerlink" title="VaR"></a>VaR</h2><p>Under a certain confidence level, the maximum possible loss of a certain financial asset or portfolio value in a specific future period.</p>]]></content>
    
    
    <categories>
      
      <category>金融</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>回测</title>
    <link href="/2023/03/03/%E9%87%91%E8%9E%8D/%E5%9B%9E%E6%B5%8B/"/>
    <url>/2023/03/03/%E9%87%91%E8%9E%8D/%E5%9B%9E%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="回测"><a href="#回测" class="headerlink" title="回测"></a>回测</h1><h2 id="常见指标"><a href="#常见指标" class="headerlink" title="常见指标"></a>常见指标</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 年化收益率</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">annualized_return</span>(<span class="hljs-params">nav</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">pow</span>(nav[-<span class="hljs-number">1</span>] / nav[<span class="hljs-number">0</span>], <span class="hljs-number">250</span> / <span class="hljs-built_in">len</span>(nav)) - <span class="hljs-number">1</span><br><span class="hljs-comment"># 年化波动率</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">annualized_vol</span>(<span class="hljs-params">nav</span>):<br>    <span class="hljs-keyword">return</span> nav.pct_change().dropna().std() * np.sqrt(<span class="hljs-number">250</span>)<br><span class="hljs-comment"># 年化夏普比率</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sharp_ratio</span>(<span class="hljs-params">nav</span>):<br>    <span class="hljs-keyword">return</span> annualized_return(nav) / annualized_vol(nav)<br><span class="hljs-comment"># 最大回撤</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_drawdown</span>(<span class="hljs-params">nav</span>):<br>    drawdown = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(nav)):<br>        cur_drawdown = nav[index] / <span class="hljs-built_in">max</span>(nav[<span class="hljs-number">0</span>:index]) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> cur_drawdown &gt; drawdown:<br>            drawdown = cur_drawdown<br>    <span class="hljs-keyword">return</span> drawdown<br></code></pre></td></tr></table></figure><h3 id="turnover"><a href="#turnover" class="headerlink" title="turnover"></a>turnover</h3><h3 id="heater-ratio"><a href="#heater-ratio" class="headerlink" title="heater ratio"></a>heater ratio</h3><p>收益率为正的1</p>]]></content>
    
    
    <categories>
      
      <category>金融</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>金融经济</title>
    <link href="/2023/03/03/%E9%87%91%E8%9E%8D/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E/"/>
    <url>/2023/03/03/%E9%87%91%E8%9E%8D/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E/</url>
    
    <content type="html"><![CDATA[<h1 id="金融经济"><a href="#金融经济" class="headerlink" title="金融经济"></a>金融经济</h1><h2 id="Alpha-Beta"><a href="#Alpha-Beta" class="headerlink" title="Alpha, Beta"></a>Alpha, Beta</h2><ul><li>alpha: For unsystematic risk, Alpha is the return that investors get unrelated to market fluctuations. It is generally used to measure investors’ investment skills.</li><li>beta: It represents the systematic risk of investment, reflecting the sensitivity of the strategy to changes in the overall market.</li></ul><h2 id="CAPM"><a href="#CAPM" class="headerlink" title="CAPM"></a>CAPM</h2><ul><li>缺陷</li></ul><h2 id="APT"><a href="#APT" class="headerlink" title="APT"></a>APT</h2><h2 id="Fama-French"><a href="#Fama-French" class="headerlink" title="Fama-French"></a>Fama-French</h2><h2 id="Barra模型"><a href="#Barra模型" class="headerlink" title="Barra模型"></a>Barra模型</h2><h2 id="什么是混沌理论？可以用它来预测股票收益率吗？如果可以，请说明为什么？"><a href="#什么是混沌理论？可以用它来预测股票收益率吗？如果可以，请说明为什么？" class="headerlink" title="什么是混沌理论？可以用它来预测股票收益率吗？如果可以，请说明为什么？"></a>什么是混沌理论？可以用它来预测股票收益率吗？如果可以，请说明为什么？</h2><p>第一问：大家可以百度出很多内容，这里不过多陈述。</p><p>第二问：如果你想预测股票收益率，建议你使用神经网络或者其他非线性模型。混论理论在自然科学中是伟大的，但它在金融中却是失败的</p><h2 id="系统性风险和非系统性风险"><a href="#系统性风险和非系统性风险" class="headerlink" title="系统性风险和非系统性风险"></a>系统性风险和非系统性风险</h2><p>Systematic risk refers to those risk factors that can affect the whole financial market, including economic cycle, changes in national macroeconomic policies, etc. Such risks cannot be offset or weakened by diversification. </p><p>Non systematic risk is a risk related to a specific company or industry, and it has nothing to do with economic, political and other factors that affect all financial variables. By diversifying investment, non systematic risks can be reduced, and if diversification is sufficient and effective, such risks can also be eliminated.</p>]]></content>
    
    
    <categories>
      
      <category>金融</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Brain Teasers</title>
    <link href="/2023/03/03/%E6%95%B0%E5%AD%A6/Brain%20Teasers/"/>
    <url>/2023/03/03/%E6%95%B0%E5%AD%A6/Brain%20Teasers/</url>
    
    <content type="html"><![CDATA[<h1 id="Brain-Teasers"><a href="#Brain-Teasers" class="headerlink" title="Brain Teasers"></a>Brain Teasers</h1><h2 id="你在一个战场上看守着-100个凶手，而你的枪只有一颗子弹。如果任何一个凶手的生还几率不是零，他就会试图逃跑。如果凶手确已死亡，他就不会企图逃跑。你如何阻止他们逃跑"><a href="#你在一个战场上看守着-100个凶手，而你的枪只有一颗子弹。如果任何一个凶手的生还几率不是零，他就会试图逃跑。如果凶手确已死亡，他就不会企图逃跑。你如何阻止他们逃跑" class="headerlink" title="你在一个战场上看守着 100个凶手，而你的枪只有一颗子弹。如果任何一个凶手的生还几率不是零，他就会试图逃跑。如果凶手确已死亡，他就不会企图逃跑。你如何阻止他们逃跑?"></a>你在一个战场上看守着 100个凶手，而你的枪只有一颗子弹。如果任何一个凶手的生还几率不是零，他就会试图逃跑。如果凶手确已死亡，他就不会企图逃跑。你如何阻止他们逃跑?</h2><h2 id="100-人排队登上一架正好有-100-个座位的飞机。每位乘客都有一张分配到特定座位的机票。第一个上车的人喝醉了，随便找了个座位坐下。其余的旅客如果发现分配给他们的座位是空的，就会坐进去。如果他们发现自己的座位有人坐，他们会随机选择一个座位。大家都上了车，都坐好了。最后一个登机人坐在指定座位上的概率是多少"><a href="#100-人排队登上一架正好有-100-个座位的飞机。每位乘客都有一张分配到特定座位的机票。第一个上车的人喝醉了，随便找了个座位坐下。其余的旅客如果发现分配给他们的座位是空的，就会坐进去。如果他们发现自己的座位有人坐，他们会随机选择一个座位。大家都上了车，都坐好了。最后一个登机人坐在指定座位上的概率是多少" class="headerlink" title="100 人排队登上一架正好有 100 个座位的飞机。每位乘客都有一张分配到特定座位的机票。第一个上车的人喝醉了，随便找了个座位坐下。其余的旅客如果发现分配给他们的座位是空的，就会坐进去。如果他们发现自己的座位有人坐，他们会随机选择一个座位。大家都上了车，都坐好了。最后一个登机人坐在指定座位上的概率是多少?"></a>100 人排队登上一架正好有 100 个座位的飞机。每位乘客都有一张分配到特定座位的机票。第一个上车的人喝醉了，随便找了个座位坐下。其余的旅客如果发现分配给他们的座位是空的，就会坐进去。如果他们发现自己的座位有人坐，他们会随机选择一个座位。大家都上了车，都坐好了。最后一个登机人坐在指定座位上的概率是多少?</h2><p>令$p_n$为n个人坐在指定座位上的概率。要确定$p_{100}$。设A为最后一个人坐在自己座位上的事件，$B_i$为当还有i个座位时上车的人选择的座位号。遵循1到i的离散均匀分布，因此$P(B_i &#x3D; k) &#x3D; \frac{1}{i}$，因为有i个座位，人们随机选择一个。从n&#x3D;1的情况开始</p><h2 id="100-的阶乘（100-）后面有多少个零？"><a href="#100-的阶乘（100-）后面有多少个零？" class="headerlink" title="100 的阶乘（100!）后面有多少个零？"></a>100 的阶乘（100!）后面有多少个零？</h2><p>因为10&#x3D;2$\times$5，所以0的个数就是100!因式分解后2$\times$5（必须配对）的个数。显然因式分解中2的个数比5多，因此问题划归为5的个数决定了后面0的数量。先来数5因子有几个：在100 内，5作为因子的数有5, 10, 15, 20, 25… 总共有20个。但是注意到25, 50, 75, 100都包含了2个5作为因子（25&#x3D;1$\times$5$\times$5, 50&#x3D;2$\times$5$\times$5等）。因此对于这些数要多数一次。所以总共就是有24个5因子，100!后面有24个0。</p><h2 id="来自不同银行的-8-位宽客聚在一起喝酒。他们都想知道在坐-8-个人的平均工资。然而，每个人都不愿意向其他人透露自己的薪水。你能想出一个策略让这-8-个人在不知道别人薪水的情况下计算出在座各位稍微平均工资吗？"><a href="#来自不同银行的-8-位宽客聚在一起喝酒。他们都想知道在坐-8-个人的平均工资。然而，每个人都不愿意向其他人透露自己的薪水。你能想出一个策略让这-8-个人在不知道别人薪水的情况下计算出在座各位稍微平均工资吗？" class="headerlink" title="来自不同银行的 8 位宽客聚在一起喝酒。他们都想知道在坐 8 个人的平均工资。然而，每个人都不愿意向其他人透露自己的薪水。你能想出一个策略让这 8 个人在不知道别人薪水的情况下计算出在座各位稍微平均工资吗？"></a>来自不同银行的 8 位宽客聚在一起喝酒。他们都想知道在坐 8 个人的平均工资。然而，每个人都不愿意向其他人透露自己的薪水。你能想出一个策略让这 8 个人在不知道别人薪水的情况下计算出在座各位稍微平均工资吗？</h2><p>让第1个宽客选择一个随机数a，把这个随机数加到他的工资中，假设这个数是b。第2个宽客把他自己的工资加到b中，按照这个方法，依次到第8个宽客，假设最后结果是c，同时第八个宽客把结果c再给到第一个宽客手中。然后第一个宽客从c中减去a得到d，最后将d除以8，就得到了大家的平均工资。</p><h2 id="一栋大楼有三部电梯，你怎么安排这三部电梯是这个大楼各楼层的人都能最快的按到自己想要的电梯"><a href="#一栋大楼有三部电梯，你怎么安排这三部电梯是这个大楼各楼层的人都能最快的按到自己想要的电梯" class="headerlink" title="一栋大楼有三部电梯，你怎么安排这三部电梯是这个大楼各楼层的人都能最快的按到自己想要的电梯"></a>一栋大楼有三部电梯，你怎么安排这三部电梯是这个大楼各楼层的人都能最快的按到自己想要的电梯</h2><h2 id="e-pi-和-pi-e-哪个大"><a href="#e-pi-和-pi-e-哪个大" class="headerlink" title="$e^\pi$和$\pi^e$哪个大"></a>$e^\pi$和$\pi^e$哪个大</h2><p>两边取对数<br>$$<br>a&#x3D;lne^\pi&#x3D;\pi\<br>b&#x3D;ln\pi ^e&#x3D;eln\pi<br>$$<br>构造函数<br>$$<br>f(x)&#x3D;x-elnx<br>$$<br>令<br>$$<br>f’(x)&#x3D;1-\frac{e}{x}&#x3D;0<br>$$<br>则<br>$$<br>x&#x3D;e为极小值点<br>$$<br>而$\pi&gt;e$，所以$e^\pi&gt;\pi^e$</p><h2 id="你在一个木板的x位置，5是末端，0是起点，每次你有一半概率向左走或向右走，问最终走到末端的概率"><a href="#你在一个木板的x位置，5是末端，0是起点，每次你有一半概率向左走或向右走，问最终走到末端的概率" class="headerlink" title="你在一个木板的x位置，5是末端，0是起点，每次你有一半概率向左走或向右走，问最终走到末端的概率"></a>你在一个木板的x位置，5是末端，0是起点，每次你有一半概率向左走或向右走，问最终走到末端的概率</h2><h2 id="如果-x-land-x-land-x-land-…-x3D-2-，求-x"><a href="#如果-x-land-x-land-x-land-…-x3D-2-，求-x" class="headerlink" title="如果$x\land x\land x\land …&#x3D;2$，求$x$"></a>如果$x\land x\land x\land …&#x3D;2$，求$x$</h2><p>$$<br>\underset{n\rightarrow \infty}{\lim}\frac{x\land x\land x\land …}{n}&#x3D;2 \Leftrightarrow \underset{n\rightarrow \infty}{\lim}\frac{x\land x\land x\land …}{n-1}&#x3D;2<br>$$</p><p>则当n 趋近于无穷大时，加上或减去一个$x\land$应该会得到相同的结果：<br>$$<br>x\land x\land x\land …&#x3D;x\land(x\land x\land  …)&#x3D;x\land 2\Rightarrow x&#x3D;\sqrt{2}<br>$$</p><h2 id="一个钟表（按顺时针方向编号1-12）从墙上掉了下来，摔成三块。你会发现每一块上的数字之和是相等的。那么，每一块上的数字是多少呢？"><a href="#一个钟表（按顺时针方向编号1-12）从墙上掉了下来，摔成三块。你会发现每一块上的数字之和是相等的。那么，每一块上的数字是多少呢？" class="headerlink" title="一个钟表（按顺时针方向编号1-12）从墙上掉了下来，摔成三块。你会发现每一块上的数字之和是相等的。那么，每一块上的数字是多少呢？"></a>一个钟表（按顺时针方向编号1-12）从墙上掉了下来，摔成三块。你会发现每一块上的数字之和是相等的。那么，每一块上的数字是多少呢？</h2><p>使用求和方程，(1+12)*12&#x2F;2&#x3D;78，所以每一块的数字和必须是26，每一块上的数字必须是连续的，因为题目已经说明不允许有奇形怪状的碎块，我们很容易知道：5+6+7+8&#x3D;26，但是为什么再找不到更多的连续数字加起来是26呢？</p><p>这样的假设从12点到1点在钟表上就不正确了。一旦这个错误的假设被消除，那我们的思路就变得很明朗：12+1&#x3D;13，11+2&#x3D;13。因此第二个碎块应该是11，12，1，2。那最后一块自然而然就是3，4，9，10。</p><h2 id="假设有98个不同的整数从1到100。有什么好的方法找出两个缺失的整数在-1-100-内？"><a href="#假设有98个不同的整数从1到100。有什么好的方法找出两个缺失的整数在-1-100-内？" class="headerlink" title="假设有98个不同的整数从1到100。有什么好的方法找出两个缺失的整数在[1,100]内？"></a>假设有98个不同的整数从1到100。有什么好的方法找出两个缺失的整数在[1,100]内？</h2><p>将缺失的整数表示为$x$和$y$。现有的整数表示为$z_1$到$z_{98}$。应用求和方程：</p><p>$$<br>\sum_{n&#x3D;1}^{100} n&#x3D;x+y+\sum_{i&#x3D;1}^{98} z_i \Rightarrow x+y&#x3D;\frac{102\times 101}{2}-\sum_{i&#x3D;1}^{98}z_i<br>$$<br>$$<br>\sum_{n&#x3D;1}^{100}n^2&#x3D;x^2+y^2+\sum_{i&#x3D;1}^{98}z_i^2\Rightarrow x^2+y^2&#x3D;\frac{100\times 101 \times 201}{6}-\sum_{i&#x3D;1}^{98}z_i^2<br>$$<br>【$\sum^n_{i&#x3D;1}\limits i^2&#x3D;\frac{n(n+1)(2n+1)}{6}$】</p><p>通过上面两个方程可以解出x和y。</p><h2 id="BO3-tennis-game，bet-on-two-games-or-three-games"><a href="#BO3-tennis-game，bet-on-two-games-or-three-games" class="headerlink" title="BO3 tennis game，bet on two games or three games?"></a>BO3 tennis game，bet on two games or three games?</h2><p>设A、B赢的概率分别是p，q</p><p>两场结束的概率：$p^2+q^2$</p><p>三场结束的概率：$2pq$</p>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>随机过程</title>
    <link href="/2023/03/03/%E6%95%B0%E5%AD%A6/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/"/>
    <url>/2023/03/03/%E6%95%B0%E5%AD%A6/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="随机过程"><a href="#随机过程" class="headerlink" title="随机过程"></a>随机过程</h1><h2 id="鞅"><a href="#鞅" class="headerlink" title="鞅"></a>鞅</h2><h3 id="停时"><a href="#停时" class="headerlink" title="停时"></a>停时</h3><p>假如你在做地铁，但是你没有地铁路程图，如果别人和你说到什么站做什么事，然后你坐车到了那个站，你看见站牌名，就知道你可以开始行动了。这就是停时。</p>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>岭回归和LASSO回归</title>
    <link href="/2023/03/03/%E6%95%B0%E5%AD%A6/%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%92%8CLASSO%E5%9B%9E%E5%BD%92/"/>
    <url>/2023/03/03/%E6%95%B0%E5%AD%A6/%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%92%8CLASSO%E5%9B%9E%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<h1 id="岭回归和LASSO回归"><a href="#岭回归和LASSO回归" class="headerlink" title="岭回归和LASSO回归"></a>岭回归和LASSO回归</h1><h2 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h2><p>和Beyesian回归比较</p><p>和PCA比较<br>$$<br>L(\beta)&#x3D;||Y-X\beta||^2+\lambda ||\beta||^2<br>$$</p><p>Ridge regression penalizes coefficients with L2 regularization. Ridge regression can decrease some coefficients, but can not select features. And it has closed form. Under the condition of many small&#x2F;medium sized effects, using ridge regression is better. </p><ul><li>有偏估计</li></ul><h3 id="岭回归vs线性回归"><a href="#岭回归vs线性回归" class="headerlink" title="岭回归vs线性回归"></a>岭回归vs线性回归</h3><p>线性回归和岭回归都是线性模型，用于拟合数据之间的线性关系。它们的主要区别在于模型复杂度的控制和正则化项的引入。</p><p>通常来说，当训练数据的特征数比样本数大很多，或者特征之间存在多重共线性（即某些特征之间存在较高的相关性），线性回归的表现会比较差，此时可以使用岭回归。</p><p>另外，在存在离群点（outlier）的情况下，线性回归的表现也可能较差，因为离群点会对模型产生较大的影响。此时，可以使用带有正则化项的岭回归来降低离群点的影响。</p><p>总之，当样本数比特征数多，且不存在多重共线性或离群点时，线性回归可能会是更好的选择；而当特征数比样本数大或存在多重共线性或离群点时，岭回归可能会表现更好。当然，最好的方法是尝试不同的模型并进行比较。</p><h2 id="LASSO回归"><a href="#LASSO回归" class="headerlink" title="LASSO回归"></a>LASSO回归</h2><p>$$<br>L(\beta)&#x3D;||Y-X\beta||^2+\lambda ||\beta||^1<br>$$</p><p>LASSO regression penalizes coefficients with L1 regularization. LASSO regression can make some coefficients exactly equal to 0, achieving feature selection. But it has no closed form. Under the condition of only a few variables with medium&#x2F;large effect, using LASSO regression is better</p><h2 id="岭回归-vs-LASSO回归"><a href="#岭回归-vs-LASSO回归" class="headerlink" title="岭回归 vs LASSO回归"></a>岭回归 vs LASSO回归</h2><p>岭回归和Lasso回归是两种经典的正则化线性回归算法，它们都是通过在代价函数中引入正则化项来控制模型复杂度，避免过拟合。两者的主要区别在于使用的正则化项不同，岭回归使用L2正则化，而Lasso回归使用L1正则化。这两种正则化方式对应的参数惩罚项分别是参数平方和和参数绝对值和。</p><h3 id="岭回归的优势"><a href="#岭回归的优势" class="headerlink" title="岭回归的优势"></a>岭回归的优势</h3><ol><li>可以处理多重共线性：当数据中存在多个高度相关的自变量时，最小二乘回归会导致过拟合，而岭回归可以通过对参数进行平滑处理，减小多重共线性的影响，提高模型的鲁棒性。</li><li>对异常值不敏感：由于岭回归对参数进行了平滑处理，因此可以有效地降低异常值的影响，提高模型的稳定性。</li><li>可以得到更加稳定的结果：由于岭回归引入的L2正则化项能够控制模型的复杂度，因此可以有效地减小模型的方差，降低模型的波动性，从而得到更加稳定的结果。</li></ol><h3 id="Lasso回归的优势"><a href="#Lasso回归的优势" class="headerlink" title="Lasso回归的优势"></a>Lasso回归的优势</h3><ol><li>可以进行特征选择：由于L1正则化倾向于将一些参数压缩到0，因此可以用于特征选择，即通过Lasso回归来筛选出对目标变量有重要影响的特征，从而减小模型的复杂度。</li><li>可以用于稀疏数据集：在处理稀疏数据集时，Lasso回归通常比岭回归更为有效，因为L1正则化能够将某些系数压缩为0，从而能够更好地处理稀疏数据。</li></ol><p>综上所述，岭回归和Lasso回归都是非常实用的线性回归算法，在不同的应用场景下具有不同的优势。如果数据集中存在多重共线性，或者需要得到更加稳定的结果，岭回归可能更加合适；而如果需要进行特征选择或者处理稀疏数据集，则Lasso回归可能更加适用。</p><h3 id="Ridge-vs-LASSO稀疏解"><a href="#Ridge-vs-LASSO稀疏解" class="headerlink" title="Ridge vs LASSO稀疏解"></a>Ridge vs LASSO稀疏解</h3><p>图中彩色线条即为目标函数的等高线，黑色线条即为约束条件。根据岭回归和套索回归的约束条件，分别得到下图两个图像。</p><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20230131092039.png"></p><p>右图为LASSO回归图像，目标函数的等高线，大部分时候都会在角的地方相交。例如图中所示，横坐标 $\hat{\beta}_1$即为0，因此就产生了稀疏性【在高纬度情况下，同样道理】；而在岭回归的图像中，约束条件画出来是一个圆，所以相交的地方出现在具有稀疏性的位置的概率就变得非常小了。<strong>这就从直观上来解释了为什么LASSO回归能产生稀疏性，而岭回归不行的原因了。</strong></p>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
      <category>回归</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>线性回归</title>
    <link href="/2023/03/03/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <url>/2023/03/03/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><h2 id="基本假设"><a href="#基本假设" class="headerlink" title="基本假设"></a>基本假设</h2><ol><li>The Two Variables Should be in a Linear Relationship<ul><li>检验方法：散点图</li></ul></li><li>residuals follow normal distribution<ul><li>检验方法：QQ图（quantile of target distribution and sample distribution, if the data points are distributed near the straight line y&#x3D;x)或ks检验</li></ul></li><li>There Should be No Multicollinearity in the Data多重共线性<ul><li>Independent variables shall be independent of each other</li><li>检验方法：<ul><li>VIF (variance inflation factor)(&lt;10 is ok), $VIF&#x3D;\frac{1}{1-R^2}$，$R^2$ is the multiple correlation coefficient of linear regression with this variable as the dependent variable and the other variables as the independent variables. 表示It represents the variance of the regression coefficient estimator over the variance when the independent variables without multicollinearity</li><li>correlation matrix</li></ul></li></ul></li><li>There Should be No Autocorrelation in the Data自相关性<ul><li>The residuals should be independent of each other.</li><li>检验方法：DW Statistics</li></ul></li><li>There Should be Homoscedasticity Among the Data同方差性<ul><li>The variance of the residuals should be constant</li><li>检验方法：White Test</li></ul></li></ol><h2 id="BLUE"><a href="#BLUE" class="headerlink" title="BLUE"></a>BLUE</h2><p>在经典假设下，OLS估计量估计量具有，线性、无偏性和有效性三个优良性质，称为最佳线性无偏估计量（best linear unbiased estimator,BLUE）</p><h2 id="怎么看残差是否符合假设"><a href="#怎么看残差是否符合假设" class="headerlink" title="怎么看残差是否符合假设"></a>怎么看残差是否符合假设</h2><h2 id="线性回归，比如残差不符合假设，有没有其他觉得线性模型不好的地方"><a href="#线性回归，比如残差不符合假设，有没有其他觉得线性模型不好的地方" class="headerlink" title="线性回归，比如残差不符合假设，有没有其他觉得线性模型不好的地方"></a>线性回归，比如残差不符合假设，有没有其他觉得线性模型不好的地方</h2><h2 id="怎么检验多重共线性（2种方法，vix，相关系数矩阵）"><a href="#怎么检验多重共线性（2种方法，vix，相关系数矩阵）" class="headerlink" title="怎么检验多重共线性（2种方法，vix，相关系数矩阵）"></a>怎么检验多重共线性（2种方法，vix，相关系数矩阵）</h2><h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><h3 id="R-2"><a href="#R-2" class="headerlink" title="$R^2$"></a>$R^2$</h3><p>R²是指拟合优度，是回归直线对观测值的拟合程度。</p><p>表达式：<br>$$<br>R^2&#x3D;SSR&#x2F;SST&#x3D;1-SSE&#x2F;SST&#x3D;\frac{Var(\hat{y})}{Var(y)}<br>$$</p><p>其中：SST&#x3D;SSR+SSE，SST(total sum of squares)为总平方和，SSR(regression sum of squares)为回归平方和，SSE(error sum of squares) 为残差平方和。</p><p>回归平方和：SSR(Sum of Squares forregression) &#x3D; ESS (explained sum of squares)</p><p>残差平方和：SSE（Sum of Squares for Error） &#x3D; RSS(residual sum of squares)</p><p>总离差平方和：SST(Sum of Squares fortotal) &#x3D; TSS(total sum of squares)</p><p>SSE+SSR&#x3D;SST RSS+ESS&#x3D;TSS</p><p>$$<br>SSR&#x3D;\sum^n_{i&#x3D;1}(\hat{y_i}-\bar{y})^2\<br>SSE&#x3D;\sum^n_{i&#x3D;1}(\hat{y_i}-y_i)^2\<br>SST&#x3D;\sum^n_{i&#x3D;1}(y_i-\bar{y})^2<br>$$</p><h5 id=""><a href="#" class="headerlink" title=""></a></h5><p>$$<br>R^2&#x3D;\frac{ESS}{TSS}&#x3D;1-\frac{RSS}{TSS}<br>$$</p><p>$$<br>TSS&#x3D;ESS+RSS\<br>\sum(y_i-\bar{y})^2&#x3D;\sum (\hat{y}_i-\bar{y})^2+\sum e_i^2<br>$$</p><p>因变量的变化有多少比例可以由自变量解释</p><h4 id="样本外-R-2-为负数"><a href="#样本外-R-2-为负数" class="headerlink" title="样本外$R^2$为负数"></a>样本外$R^2$为负数</h4><p>SSE&gt;SST</p><h4 id="调整-R-2-（很多变量）"><a href="#调整-R-2-（很多变量）" class="headerlink" title="调整$R^2$（很多变量）"></a>调整$R^2$（很多变量）</h4><p>The adjusted R square takes into account the influence of sample size and the number of independent variables in the regression.</p><p>$R^2$问题：增加自变量的个数会使$R^2$增大</p><p>解决方法：调整$R^2$<br>$$<br>R_{adj}&#x3D;1-\frac{\frac{RSS}{n-p-1}}{\frac{TSS}{n-1}}<br>$$<br>$p$是自变量个数，$n$是样本数量</p>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
      <category>回归</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>统计</title>
    <link href="/2023/03/03/%E6%95%B0%E5%AD%A6/%E7%BB%9F%E8%AE%A1/"/>
    <url>/2023/03/03/%E6%95%B0%E5%AD%A6/%E7%BB%9F%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h1><h2 id="好的estimator"><a href="#好的estimator" class="headerlink" title="好的estimator"></a>好的estimator</h2><ol><li>unbiased: on average they yield an estimate that equals the real parameter</li></ol><p>$$<br>E[\mu]&#x3D;\hat{\mu}\<br>E[\sigma^2]&#x3D;\hat{\sigma}^2<br>$$</p><ol start="2"><li>low variance: variance that is lower than any other possible estimator</li></ol><p>$$<br>   Var(\mu)&#x3D;E[(\hat{\mu}-\mu)^2]\<br>   Var(\sigma^2)&#x3D;E[(\hat{\sigma}^2-\sigma^2)^2]\<br>$$</p><h2 id="样本方差的分母为什么是n-1，而不是n？"><a href="#样本方差的分母为什么是n-1，而不是n？" class="headerlink" title="样本方差的分母为什么是n-1，而不是n？"></a>样本方差的分母为什么是n-1，而不是n？</h2><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20220912113632.png"></p><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20220912113646.png"></p><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20220912113657.png"></p><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20220912113712.png"></p><h2 id="数据有偏差时相关统计量如何改变"><a href="#数据有偏差时相关统计量如何改变" class="headerlink" title="数据有偏差时相关统计量如何改变"></a>数据有偏差时相关统计量如何改变</h2><p>[对一些非常经典的模型做出一定调整]</p><h2 id="P值"><a href="#P值" class="headerlink" title="P值"></a>P值</h2><p>p值是在假定原假设为真时，得到与样本相同或者更极端的结果的概率。</p><p>P值很小则拒绝原假设</p><h2 id="第一类错误，第二类错误"><a href="#第一类错误，第二类错误" class="headerlink" title="第一类错误，第二类错误"></a>第一类错误，第二类错误</h2><ul><li>I：$P(拒绝H_0|H_0)$，弃真，原假设为真但拒绝原假设</li><li>II：$P(接受H_0|H_1)$，存伪，原假设伪假但接受原假设</li></ul><p>功效&#x3D;1-第二类错误概率<br>$$<br>功效&#x3D;1-P(接受H_0|H_1)&#x3D;P(拒绝H_0|H_1)<br>$$<br>知道第一类错误发生概率，不知道第二类错误发生概率，所以拒绝原假设比较理直气壮，接受原假设没有把握</p><ul><li>一、二类错误此消彼长，要都减少只能<strong>增加样本容量</strong></li><li>假设检验时一般指定可接受<strong>一类错误</strong>的最大概率（<strong>显著性水平</strong>）</li></ul><h2 id="MLE"><a href="#MLE" class="headerlink" title="MLE"></a>MLE</h2><p>缺点：</p><ul><li>数据量小性能差</li><li>$\theta$是个唯一值，没有别的参数可用，如果他错了那整个模型就错了</li></ul>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>线代</title>
    <link href="/2023/03/03/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E4%BB%A3/"/>
    <url>/2023/03/03/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E4%BB%A3/</url>
    
    <content type="html"><![CDATA[<h1 id="线代"><a href="#线代" class="headerlink" title="线代"></a>线代</h1><h2 id="特征向量和特征值"><a href="#特征向量和特征值" class="headerlink" title="特征向量和特征值"></a>特征向量和特征值</h2><p>矩阵$A$，向量$v$，常量$\lambda$<br>$$<br>Av&#x3D;\lambda v<br>$$<br>矩阵乘向量：把向量transform，改变向量的大小和方向</p><ul><li><p>特征向量：所有transform以后不改变方向，只改变大小的向量的集合</p></li><li><p>特征值：向量改变大小的程度$\lambda$</p></li></ul><h3 id="求特征值"><a href="#求特征值" class="headerlink" title="求特征值"></a>求特征值</h3><p>$$<br>Av&#x3D;\lambda v\<br>$$<br>$$<br>Av&#x3D;\lambda I v\<br>$$<br>$$<br>(A-\lambda I)v&#x3D;0→两个矩阵都非满秩\<br>$$<br>$$<br>|A-\lambda I|&#x3D;0<br>$$</p><h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><p>特征向量给了我们它被拉伸或转化的方向，而特征值是它被拉伸的数值</p><p>协方差矩阵：有助于比较一只股票从其平均值的变动是如何依赖于另一只股票从其平均值的变动</p><p>协方差矩阵的特征值之和大约等于我们原始矩阵的总方差之和</p><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol><li>标准化</li><li>计算协方差矩阵的特征值特征向量</li><li>对原来的矩阵乘特征向量矩阵</li></ol><h2 id="方差、协方差矩阵"><a href="#方差、协方差矩阵" class="headerlink" title="方差、协方差矩阵"></a>方差、协方差矩阵</h2><p>1列为1个变量，1行为1个样本：（m行n列）<br>$$<br>Cov(X)&#x3D;E[(X-E(X))^\top (X-E(X))]\<br>$$<br>$$<br>或Cov(X)&#x3D;\frac{1}{m}(X-E(X))^\top (X-E(X))\<br>$$<br>$$<br>Var(X)&#x3D;(X-E(X))^\top (X-E(X))<br>$$<br>E(X)&#x3D;0时：<br>$$<br>Cov(X)&#x3D;E[X^\top X]\<br>$$<br>$$<br>Var(X)&#x3D;X^\top X<br>$$<br>协方差矩阵是<strong>半正定</strong>矩阵：</p><ul><li>任意非零向量$x$，有$x^\top \Sigma x\geqslant 0$</li></ul><h2 id="cholesky分解"><a href="#cholesky分解" class="headerlink" title="cholesky分解"></a>cholesky分解</h2><p>正定矩阵<br>$$<br>A&#x3D;LL^\top，L是下三角矩阵<br>$$</p><h3 id="蒙特卡洛模拟whitening（cholesky分解）"><a href="#蒙特卡洛模拟whitening（cholesky分解）" class="headerlink" title="蒙特卡洛模拟whitening（cholesky分解）"></a>蒙特卡洛模拟whitening（cholesky分解）</h3><p>行：</p><p>$X$是每一行为一个随机变量的矩阵，协方差矩阵为$M$，均值为0，则<br>$$<br>M&#x3D;E[XX^\top]<br>$$<br>因为$M$是对称的半正定矩阵，有平方根$M^\frac{1}{2}$（不一定要对称），满足$M^\frac{1}{2}(M^\frac{1}{2})^\top&#x3D;M$。如果$M$是正定的，$M^\frac{1}{2}$可逆。矩阵$Y&#x3D;M^{-\frac{1}{2}}X$有协方差矩阵：</p><p>$$<br>Cov(Y)&#x3D;E[YY^\top]&#x3D;M^{-\frac{1}{2}}E[XX^\top] (M^{-\frac{1}{2}})^\top&#x3D;M^{-\frac{1}{2}}M(M^{-\frac{1}{2}})^\top\<br>$$<br>$$<br>&#x3D;M^{-\frac{1}{2}}(M^{\frac{1}{2}}(M^{\frac{1}{2}})^\top)(M^{-\frac{1}{2}})^\top&#x3D;(M^{-\frac{1}{2}}M^{\frac{1}{2}})(M^{-\frac{1}{2}}M^{\frac{1}{2}})^\top&#x3D;I<br>$$</p><p>其中$M^\frac{1}{2}$可以通过cholesky分解得到$L$，$M&#x3D;LL^\top$。如果$M$是正定的，$L$可逆。矩阵$Y&#x3D;L^{-1}X$有协方差矩阵：<br>$$<br>Cov(Y)&#x3D;E[YY^\top]&#x3D;L^{-1}E[XX^\top] (L^{-1})^\top&#x3D;L^{-1}M(L^{-1})^\top\<br>$$<br>$$<br>&#x3D;L^{-1}(LL^\top)(L^{-1})^\top&#x3D;(L^{-1}L)(L^{-1}L)^\top&#x3D;I<br>$$</p><p>列：</p><p>$X$是每一列为一个随机变量的矩阵，协方差矩阵为$M$，均值为0，则<br>$$<br>M&#x3D;E[X^\top X]<br>$$<br>因为$M$是对称的半正定矩阵，有平方根$M^\frac{1}{2}$（不一定要对称），满足$M^\frac{1}{2}(M^\frac{1}{2})^\top&#x3D;M$。如果$M$是正定的，$M^\frac{1}{2}$可逆。矩阵$Y&#x3D;X(M^{-\frac{1}{2}})^\top$有协方差矩阵：<br>$$<br>Cov(Y)&#x3D;E[Y^\top Y]&#x3D;M^{-\frac{1}{2}} E[X^\top X] (M^{-\frac{1}{2}})^\top&#x3D;M^{-\frac{1}{2}} M(M^{-\frac{1}{2}})^\top\<br>$$<br>$$<br>&#x3D;M^{-\frac{1}{2}}(M^{\frac{1}{2}}(M^{\frac{1}{2}})^\top)(M^{-\frac{1}{2}})^\top&#x3D;(M^{-\frac{1}{2}}M^{\frac{1}{2}})(M^{-\frac{1}{2}}M^{\frac{1}{2}})^\top&#x3D;I<br>$$</p><p>其中$M^\frac{1}{2}$可以通过cholesky分解得到$L$，$M&#x3D;LL^\top$。如果$M$是正定的，$L$可逆。矩阵$Y&#x3D;X(L^{-1})^\top$有协方差矩阵：</p><p>$$<br>Cov(Y)&#x3D;E[Y^\top Y]&#x3D;L^{-1}E[X^\top X] (L^{-1})^\top&#x3D;L^{-1}M(L^{-1})^\top\<br>$$<br>$$<br>&#x3D;L^{-1}(LL^{\top})(L^{-1})^{\top}&#x3D;(L^{-1} L)(L^{-1} L)^{\top}&#x3D;I<br>$$</p>]]></content>
    
    
    <categories>
      
      <category>数学</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>基础知识</title>
    <link href="/2023/03/03/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2023/03/03/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="bit-amp-byte"><a href="#bit-amp-byte" class="headerlink" title="bit &amp; byte"></a>bit &amp; byte</h2><ul><li>bit：表示信息的最小单位</li><li>byte：8 bit，表示256个数字。1个byte表示一个数据&#x2F;字母，2个byte表示一个汉字</li></ul><p>数据存储是以Byte为单位，数据传输大多是以bit为单位</p>]]></content>
    
    
    <categories>
      
      <category>计算机</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Python</title>
    <link href="/2023/03/03/%E8%AE%A1%E7%AE%97%E6%9C%BA/Python/"/>
    <url>/2023/03/03/%E8%AE%A1%E7%AE%97%E6%9C%BA/Python/</url>
    
    <content type="html"><![CDATA[<h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><h2 id="量化常用Python技巧"><a href="#量化常用Python技巧" class="headerlink" title="量化常用Python技巧"></a>量化常用Python技巧</h2><p>Pandas.Series 对象、向量操作、布尔索引、rolling&#x2F;apply 函数、缺失&#x2F;异常值处理、Numpy 的常用函数等等</p><h2 id="单下划线和双下划线"><a href="#单下划线和双下划线" class="headerlink" title="单下划线和双下划线"></a>单下划线和双下划线</h2><p>1、__name__：一种约定，Python内部的名字，用来与用户自定义的名字区分开，防止冲突。</p><p>2、_name：一种约定，用来指定变量私有。</p><p>3、__name：解释器用_classname__name来代替这个名字用以区别和其他类相同的命名。</p>]]></content>
    
    
    <categories>
      
      <category>计算机</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>C++</title>
    <link href="/2023/03/03/%E8%AE%A1%E7%AE%97%E6%9C%BA/C++/"/>
    <url>/2023/03/03/%E8%AE%A1%E7%AE%97%E6%9C%BA/C++/</url>
    
    <content type="html"><![CDATA[<h1 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h1><h2 id="虚函数"><a href="#虚函数" class="headerlink" title="虚函数"></a>虚函数</h2><p>类函数，子类可以各有各的实现，子类的虚函数还是虚函数</p><p>在运行期间确定对象实际类型</p><p>当一个类带有虚函数时，编译系统会为该类构造一个虚函数表（位于类内其他成员前面），是一个指针数组，存放每个虚函数的入口地址。系统在进行动态联编的时间开销很少，提高了多态性的效率</p><p>动态联编：对象指针通过虚指针找到虚表，从虚表中查找对应的虚函数地址进行调用</p><h2 id="浅拷贝-vs-深拷贝"><a href="#浅拷贝-vs-深拷贝" class="headerlink" title="浅拷贝 vs 深拷贝"></a>浅拷贝 vs 深拷贝</h2><ul><li>赋值：得到对象地址，共用对象内容，所有变量都会随之变化</li><li>浅拷贝：拷贝一层，更改<strong>引用类型</strong>（对象、数组都是引用类型）的<strong>数据</strong>时，拷贝的对象还是能被影响，如果拷贝的对象里还有子对象的话，那子对象拷贝其是也只是得到一个地址指向而已</li><li>深拷贝：递归地拷贝，更改引用类型原对象也不变</li></ul><h2 id="Python为什么比C-慢"><a href="#Python为什么比C-慢" class="headerlink" title="Python为什么比C++慢"></a>Python为什么比C++慢</h2><p>Python is interpreted and executed sentence by sentence, with a high degree of abstraction. c++ is compiled first and converted to machine code, without dynamic typing or dynamic checking.</p>]]></content>
    
    
    <categories>
      
      <category>计算机</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>神经网络</title>
    <link href="/2023/03/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2023/03/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><ul><li><p>神经元：函数（第一层是每一个像素点，隐层是零件一步步组装的过程）</p></li><li><p>权重：关注什么样的像素图案</p></li><li><p>bias：加权和要有多大才能使神经元的激活有意义</p></li></ul><p>$$<br>a^{(1)}&#x3D;\sigma(Wa^{(0)}+b)<br>$$</p><p>其中$a$是某一层的神经元向量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Network</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args, **kwargs</span>):<br>        <span class="hljs-keyword">pass</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">feedforward</span>(<span class="hljs-params">self, a</span>):<br>        <span class="hljs-keyword">for</span> b, w <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.biases, self.weights):<br>            a = sigmoid(np.dot(w, a) + b)<br>        <span class="hljs-keyword">return</span> a<br></code></pre></td></tr></table></figure><ul><li>ReLU函数$ReLU(a)&#x3D;max(0, a)$比sigmoid函数更好训练</li></ul><h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>单个样本的cost：</p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220322214549.png" style="zoom:50%;" /><p>损失：样本的平均cost</p><p>函数的梯度指出了函数最陡的增长方向，所以沿梯度的负方向走函数值下降得最快</p><h3 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h3><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220323150037.png"></p><ul><li>随机梯度下降：划分minibatch（比如一个minibatch是100个样本），用minibatch的平均改变值代替负梯度（全部样本的平均改变值）</li></ul><p>【醉汉下山法】</p><p>假设每层只有1个神经元：</p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220323151113.png"></p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220323151332.png"></p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220323151213.png"></p><p>负梯度：</p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220323151247.png"></p><p>拓展到多个神经元：</p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220323151620.png"></p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><ul><li>非线性：导数不是常数，多层网络不退化成单层网络</li><li>几乎处处可为：保证优化中梯度的可计算性</li><li>计算简单</li></ul><h4 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h4><p>缺点：</p><ul><li>计算量大，反向传播求误差梯度时，求导复杂</li><li>反向传播的时候，很容易出现梯度消失的情况，从而无法完成深度神经网络的训练（导数从0开始，很快又趋近于0）</li></ul><h4 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h4><p>优点：梯度不会消失，计算速度很快，收敛很快</p><p>缺点：输出不是0均值</p><p>dead relu problem，某些神经元可能永远不会激活，导致参数不会更新</p><h4 id="softmax函数"><a href="#softmax函数" class="headerlink" title="softmax函数"></a>softmax函数</h4><p>multiclassification</p><h4 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h4><p>是0均值</p><p>梯度消失问题，但是缓解了一点</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><h4 id="交叉熵-cross-entropy-loss-function"><a href="#交叉熵-cross-entropy-loss-function" class="headerlink" title="交叉熵 cross entropy loss function"></a>交叉熵 cross entropy loss function</h4><p>用于衡量两个分布之间的距离</p><p>逻辑回归</p><p>logLoss (对数损失函数，LR)</p><p>hinge loss (合页损失函数，SVM)</p><p>exp-loss (指数损失函数，AdaBoost)</p><p>cross-entropy loss (交叉熵损失函数，Softmax)</p><p>quadratic loss (平方误差损失函数，线性回归)</p><p>absolution loss (绝对值损失函数， )</p><p>0-1 loss (0-1损失函数)</p><h3 id="层"><a href="#层" class="headerlink" title="层"></a>层</h3><p>图像处理：</p><p>input→（卷积层$\times$N+池化层）$\times$M→全连接层$\times$K→output</p><h4 id="全连接层-Fully-Connected-Layer"><a href="#全连接层-Fully-Connected-Layer" class="headerlink" title="全连接层 Fully Connected Layer"></a>全连接层 Fully Connected Layer</h4><h4 id="卷积层-Convolutional-layer"><a href="#卷积层-Convolutional-layer" class="headerlink" title="卷积层 Convolutional layer"></a>卷积层 Convolutional layer</h4><ul><li>局部感知野</li><li>参数共享</li></ul><h4 id="池化层-pooling-layer"><a href="#池化层-pooling-layer" class="headerlink" title="池化层 pooling layer"></a>池化层 pooling layer</h4><ul><li>使特征图变小，简化网络</li><li>特征压缩，提取主要特征</li></ul><p>常用池化层：</p><ul><li>最大池化</li><li>平均池化</li></ul><h3 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a>迭代</h3><ul><li><p>epoch：用训练集所有样本对模型进行一次完整训练</p></li><li><p>batch：用训练集中一小部分样本对模型权重进行一次反向传播的参数更新</p></li><li><p>iteration：用一个batch的数据对模型进行一次参数更新的过程</p></li></ul><p>梯度下降：</p><table><thead><tr><th>梯度下降方式</th><th>Training Set Size</th><th>Batch Size</th><th>Number of Batches</th></tr></thead><tbody><tr><td>BGD</td><td>N</td><td>N</td><td>1</td></tr><tr><td>SGD</td><td>N</td><td>1</td><td>N</td></tr><tr><td>Mini-Batch</td><td>N</td><td>B</td><td>N&#x2F;B</td></tr></tbody></table><h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><p>$$<br>a^{(t)}&#x3D;tanh(W_{ax}x^{(t)}+W_{aa}a^{(t-1)}+b_a)<br>$$</p><p>$$<br>\hat{y}^{(t)}&#x3D;softmax(W_{ya}a^{(t)}+b_y)<br>$$</p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220324153051.png"></p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220324154733.png"></p><p>特点：</p><ul><li>串联结构，后面结果的生成要参考前面的信息</li><li>所有特征共享同一套参数<ul><li>面对不同的输入（两个方面），能学到不同的相应的结果</li><li>极大减少了训练参数量</li><li>输入和输出数据在不同例子中可以有不同长度</li></ul></li></ul><h4 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h4><p>单个时间步的损失函数：<br>$$<br>L_t(\hat{y}_t,y_t)&#x3D;-y_tlog y_t-(1-y_t)log(1-y_t)<br>$$</p><p>整个序列的损失函数：所有时间步的损失求和</p><p>$$<br>L(\hat{y},y)&#x3D;\sum^T_{t&#x3D;1}L_t(\hat{y}_t,y_t)<br>$$</p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><h5 id="梯度消失"><a href="#梯度消失" class="headerlink" title="梯度消失"></a>梯度消失</h5><p>当序列太长时，连乘过多，容易导致梯度消失，无法将信息传递过去，参数更新只能捕捉到局部依赖关系，没法再捕捉序列之间的长期关联或依赖关系。这会导致渐变在向后传播时呈指数级收缩。由于梯度极小，内部权重几乎没有调整，因此较早的层无法进行任何学习。<br>$$<br>\frac{\partial L_t}{\partial W_x}&#x3D;\sum^t_{k&#x3D;1}[\frac{\partial L_t}{\partial O_t}\frac{\partial O_t}{\partial S_t}(\prod^t_{j&#x3D;t+1-k}\frac{\partial tanh(\theta_j)}{\partial \theta_j})X_{t+1-k}W_s^{k-1}]<br>$$<br>由于$W_s^{k-1}$很小的时候连乘会趋于0，因此会梯度消失</p><p>梯度消失解决办法：</p><ul><li><p>选择relu等梯度大部分落在常数上的激活函数。relu函数的导数在正数部分是恒等于1的，因此在深层网络中使用relu激活函数就不会导致梯度消失的问题。</p></li><li><p>batch normalization</p><p>BN就是通过对每一层的输出规范为均值和方差一致的方法，消除了权重参数放大缩小带来的影响，进而解决梯度消失的问题，或者可以理解为BN将输出从饱和区拉到了非饱和区。采用 Batch Normalization 层，对网络中计算得到中间值进行归一化，使得中 间计算结果的取值在均值为 0，方差为 1 这样的分布内。那么此时，在 sigmoid 和 tanh 中，函数取值处于中间变化较大的部分，梯度取值也相对较大</p></li></ul><h5 id="梯度爆炸"><a href="#梯度爆炸" class="headerlink" title="梯度爆炸"></a>梯度爆炸</h5><p>使网络变得不稳定。在极端情况下，权重的值变得非常大，以至于溢出，导致NaN值</p><p>解决办法：</p><ul><li>梯度修剪，观察梯度向量，如果大于某个阈值，缩放梯度向量，保证它不会太大</li><li>权重正则化：检查网络权重的大小，并惩罚产生较大权重值的损失函数</li><li>改变损失函数：把sigmoid改为ReLU，relu函数的导数在正数部分是恒等于1的，因此在深层网络中使用relu激活函数就不会导致梯度消失的问题</li></ul><h3 id="LSTM-Long-Short-Term-Memory"><a href="#LSTM-Long-Short-Term-Memory" class="headerlink" title="LSTM Long Short-Term Memory"></a>LSTM Long Short-Term Memory</h3><p>RNN：想把所有东西记住，不管有没有用</p><p>LSTM：设计记忆细胞，具备选择性记忆的功能，记忆重要信息，过滤掉噪声信息，减轻记忆负担</p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220324162626.png"></p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220324164635.png"></p><ul><li>$C_t$，记忆细胞：在LSTM每个时间步里面都有一个以及细胞，让LSTM有能力自由选择每个时间步里记忆的内容。</li><li>$h_t$，状态：【本门考试分数】</li><li>$f_t$，遗忘门：[0, 1]的向量，选择性遗忘上一个时间步带来的记忆【遗忘复习高数时对线代无关的记忆】</li><li>$i_t$，输入门：[0, 1]的向量，选择性保留这一个时间步新生成的记忆（来自$X_t$）【复习线代获得的记忆】</li></ul><p>$$<br>C_t&#x3D;f_tC_{t-1}+i_t\tilde{C_t}<br>$$</p><ul><li>$o_t$，输出门：【只用到其中一部分记忆用来答题】</li><li>tanh：【记忆转化为答题能力的过程】</li></ul><h4 id="LSTM优点"><a href="#LSTM优点" class="headerlink" title="LSTM优点"></a>LSTM优点</h4><ul><li>缓解RNN的梯度消失问题：通过调节$W_{hf},W_{hi},W_{hg}$可以灵活控制$\frac{\partial C_j}{\partial C_{j-1}}$的值，当要从n时刻长期记忆某个东西直到m时刻时，该路径上的$\prod_{t&#x3D;n}^m\limits \frac{\partial C_j}{\partial C_{j-1}}\approx 1\times1\times…\times1$</li></ul><h4 id="解决LSTM梯度消失问题"><a href="#解决LSTM梯度消失问题" class="headerlink" title="解决LSTM梯度消失问题"></a>解决LSTM梯度消失问题</h4><ol><li>使用门控循环单元（GRU）替代LSTM。GRU也是一种递归神经网络，可以在处理序列数据时具有与LSTM相似的记忆能力，但是GRU只有两个门控单元，因此具有更少的参数，同时也更容易训练。</li><li>使用长短期记忆网络（LSTM）的变种，如Peephole LSTM，对输入门、遗忘门和输出门进行扩展，以便更好地控制信息的流动，从而减少梯度消失的问题。</li><li>对于输入数据进行归一化处理，将其缩放到一个较小的范围内。这有助于减少梯度消失问题的影响，并使神经网络更容易训练。</li><li>使用梯度裁剪技术。这种方法可以在训练过程中对梯度进行剪切，使其不会超出一个预定的范围。这有助于避免梯度爆炸问题，并减少梯度消失的问题。</li><li>采用注意力机制（Attention Mechanism）。该方法能够使网络在处理序列数据时更加关注重要的部分，并将注意力集中在最相关的信息上，从而避免了长序列中梯度消失的问题。</li></ol><h3 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h3><p>序列预测任务是给定了n个词，去预测第n+1个词，把关注点放在前面n个词的哪一些。引入注意力机制可以更好地解释应该重点关注前面序列里的哪一些</p><h4 id="transformer和LSTM区别"><a href="#transformer和LSTM区别" class="headerlink" title="transformer和LSTM区别"></a>transformer和LSTM区别</h4><p>RNN是串行训练，要把上一步输入全部输入进来才能做下一步训练，transformer加了注意力机制可以并行训练，没有记忆力这个东西，只是通过注意力机制去找到这个东西是要关注前面的哪一些词，但并没有记得之前一共发生过什么东西</p><p>Transformer和LSTM是用于处理序列数据的两种不同的神经网络架构，它们有以下几个区别：</p><ol><li>结构不同：LSTM是一种递归神经网络，使用门控单元（如输入门、遗忘门、输出门）来控制序列中信息的流动。而Transformer则是一种基于自注意力机制的神经网络，使用多头注意力机制来对序列数据进行编码。</li><li>并行性不同：由于LSTM的递归结构，每个时间步的计算都依赖于前一个时间步的输出。这意味着LSTM在计算时必须按照时间步序列化计算，无法进行并行化处理。相比之下，Transformer的计算是全局的，可以并行计算，从而更加高效。</li><li>记忆能力不同：LSTM通过门控单元来控制信息的流动，从而具有很强的记忆能力，能够处理长序列数据。而Transformer使用自注意力机制，可以同时考虑序列中的所有位置，从而不需要像LSTM一样依赖于递归计算，因此在长序列上表现更好。</li><li>可解释性不同：由于LSTM的递归结构，很难对其内部的计算过程进行解释。而Transformer的注意力机制可以将模型的注意力集中在输入序列中的不同部分，因此更容易解释模型的决策过程。</li></ol><p>总的来说，LSTM适合处理单向、多层次、长期的时间序列数据，例如语音识别和自然语言处理。而Transformer适合处理双向、并行化、全局的时间序列数据，例如机器翻译和自然语言生成。</p><h2 id="生成对抗网络"><a href="#生成对抗网络" class="headerlink" title="生成对抗网络"></a>生成对抗网络</h2><h3 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h3><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329111525.png"></p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329112132.png"></p><ul><li>全连接层升维</li><li>把7$\times$7的数据变成28$\times$28的图像：插值（UpSampling2D）&#x2F;反卷积</li></ul><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329112427.png"></p><ul><li>图像二分类：表示层（卷积池化卷积池化），应用层</li></ul><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329112632.png"></p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329112702.png"></p><ol><li>固定G，把真实样本和generate的样本输入D，训练D</li><li>固定D，训练G</li><li>输入噪声给G，生成样本</li></ol><h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329113720.png"></p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329113745.png"></p><p>原问题化为KL散度的问题：</p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329153116.png"></p><ul><li>生成器没生成真实的样本：惩罚小</li><li>生成器生成不真实的样本：惩罚大</li></ul><p>loss偏向于生成“稳妥”的样本</p><h3 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h3><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329153349.png"></p><ul><li>训练稳定性大幅增长</li></ul><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329153517.png"></p><h3 id="CGAN"><a href="#CGAN" class="headerlink" title="CGAN"></a>CGAN</h3><p>输入G的不只是噪声，还有条件（比如红头发），把概率分布改为条件概率分布</p><h3 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h3><p>卷积神经网络+对抗神经网络</p><ul><li>在不改变GAN原理的情况下，增加增强稳定性的tricks</li></ul><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220329113339.png"></p><h2 id="防止过拟合"><a href="#防止过拟合" class="headerlink" title="防止过拟合"></a>防止过拟合</h2><ul><li>池化</li><li>dropout</li><li>early stopping</li><li>正则化</li></ul><h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p>强化学习有很多状态，要学习在每个状态下要采取什么动作。</p><p><img src="https://finclaw.oss-cn-shenzhen.aliyuncs.com/img/20220325165554.png"></p>]]></content>
    
    
    <categories>
      
      <category>计算机</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>面试题</title>
    <link href="/2023/03/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <url>/2023/03/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h1><p>Logistic回归的损失函数和梯度分别是多少、SVM的数学推导、GBDT回归的梯度代表什么</p>]]></content>
    
    
    <categories>
      
      <category>计算机</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>机器学习</title>
    <link href="/2023/03/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/03/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>以下是进行预测任务特征工程时需要考虑的关键步骤：</p><ol><li>数据探索：在开始进行特征工程之前，需要探索数据集并了解不同变量之间的关系。这可以涉及可视化数据，计算汇总统计信息，识别潜在的相关性或模式。</li><li>特征选择：并非所有特征都与特定预测任务相关或有用。特征选择涉及识别最重要的特征，并删除冗余、无关或噪声较大的特征。这可以使用相关性分析、特征重要性排名或基于模型的选择等方法实现。</li><li>特征提取：有时可用的特征可能不够信息丰富，或者需要转换以显示有用的模式或关系。特征提取涉及从现有特征中创建新特征，例如计算统计量、跨时间段聚合信息或将分类变量转换为数值形式。</li><li>特征缩放：许多机器学习模型要求特征在相似范围内进行缩放，以获得良好的性能。特征缩放涉及将数据规范化，以减少异常值的影响并确保所有特征具有相似的范围。</li><li>特征编码：分类变量在预测任务中可能会出现问题，因为需要将它们转换为数值形式。特征编码涉及将分类变量转换为可用于机器学习模型的形式，例如进行独热编码或使用标签编码。</li><li>迭代细化：特征工程通常是一个迭代过程，在每一轮特征工程后，需要监视模型的性能。这可以帮助识别需要进一步改进和微调特征工程过程的领域。</li></ol><h2 id="数据不服从高斯分布为什么也可以ML"><a href="#数据不服从高斯分布为什么也可以ML" class="headerlink" title="数据不服从高斯分布为什么也可以ML"></a>数据不服从高斯分布为什么也可以ML</h2><p>渐进理论，样本量足够大，用中心极限定理可以近似高斯分布</p><p>机器学习算法的理论基础通常建立在样本满足一些假设条件的基础上，例如正态分布或同方差性等。然而，在实际应用中，数据往往不满足这些假设条件，特别是在大数据集中，这种假设条件往往难以满足。因此，机器学习算法可以用于非正态分布数据。</p><p>以下是一些原因：</p><ol><li>机器学习算法的鲁棒性：许多机器学习算法具有一定的鲁棒性，即它们不会受到数据分布的轻微偏差的影响，而且能够在许多实际应用中表现出良好的性能。例如，决策树、随机森林和支持向量机等算法经常被用于非正态分布数据。</li><li>数据预处理：数据预处理是数据科学中的重要步骤。在处理非正态分布数据时，可以通过一些预处理技术来使数据更适合机器学习算法。例如，可以进行对数变换、幂变换或归一化等处理，以使数据更符合算法假设条件。这些技术通常可以在保持数据质量的同时提高算法的性能。</li><li>非参数方法：非参数方法是指不需要假设数据分布的一类机器学习算法。这些算法可以对非正态分布的数据建模，并能够在一些领域中取得良好的性能。例如，K近邻、神经网络和决策树等算法不需要数据分布假设，因此可以用于非正态分布数据。</li></ol><p>综上所述，尽管机器学习算法的理论基础建立在一些假设条件的基础上，但在实际应用中，这些假设条件经常难以满足。在处理非正态分布数据时，可以使用一些机器学习算法和数据预处理技术来提高模型性能，并在许多实际应用中获得良好的结果。</p><h2 id="bias-variance-tradeoff"><a href="#bias-variance-tradeoff" class="headerlink" title="bias variance tradeoff"></a>bias variance tradeoff</h2><ul><li>bias：预测值的期望和实际值的差</li><li>variance：预测值的方差</li></ul><p>嘈杂的数据集：</p><ul><li>模型复杂度越大，偏差(Bias)越小</li><li>模型复杂度越大，方差(Variance)越大</li></ul><p>通常一个模型Variance很高，意味着它往往很复杂，而复杂的模型往往会对某些样本点非常敏感，也就很可能Overfit。同样的，一个模型如果Bias很高，意味着他一直都很不准，所以Underfitting。而我们的目标则是在模型的复杂度之间找到一个平衡，从而使Bias 和Variance都尽可能低，从而得到一个Good Fitting的结果</p><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20221213155957.png"></p><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20221213155840.png"></p><h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><h3 id="ROC-AUC-Sensitivity-Specificity"><a href="#ROC-AUC-Sensitivity-Specificity" class="headerlink" title="ROC, AUC, Sensitivity, Specificity"></a>ROC, AUC, Sensitivity, Specificity</h3><ul><li><strong>真阳性率（True Positive Rate，简称TPR）</strong>：TP&#x2F;(TP+FN)，代表的含义是：实际观测为<strong>阳</strong>的样本中，模型能够正确识别出来的比例。TPR又称为Sensitivity。</li><li><strong>真阴性率（True Negative Rate，简称TNR）</strong>：TN&#x2F;(FP+TN)，代表的含义是：实际观测为<strong>阴</strong>的样本中，模型能够正确识别出来的比例。TNR又称为Specificity。</li><li><strong>假阳性率（False Positive Rate，简称FPR）</strong>：FP&#x2F;(FP+TN)，代表的含义是：实际观测为<strong>阴</strong>的样本中，被模型错误地划分成阳性的比例。FPR&#x3D;1-Specificity。</li></ul><p><strong>TPR越高、FPR越低</strong>，说明模型的预测能力越好</p><p>以FPR为横坐标、TPR为纵坐标，将每一个阈值所对应的(FPR,TPR)放入坐标系中。用红色线条将所有的点连接起来——此即为<strong>ROC曲线</strong></p><p><img src="https://jkq-pic.oss-cn-shanghai.aliyuncs.com/img/20221213104352.png"></p><p><strong>AUC</strong>：ROC曲线下的面积</p><p>优点：不受正负样本比例的影响</p><p>缺点：</p><ul><li><p>对FPR和TPR两种错误的代价同等看待</p></li><li><p>没有给出模型误差的空间分布信息</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>树</title>
    <link href="/2023/03/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E6%A0%91/"/>
    <url>/2023/03/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E6%A0%91/</url>
    
    <content type="html"><![CDATA[<h1 id="树"><a href="#树" class="headerlink" title="树"></a>树</h1><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li>因为是非参数模型，不需要对样本进行预先假设，可以处理复杂样本。</li><li>计算速度快，结果可解释性强。</li><li>可以同时处理分类和预测问题，对缺失值不敏感。</li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li>容易过拟合</li><li>特征之间存在相互关联时，数据结果表现较差。</li></ul><h4 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h4><ul><li><p>进行剪枝防止过拟合。</p><p>剪枝包括**预剪枝(Prepruning)<strong>和</strong>后剪枝(Postpruning),**前者通过对连续型变量设置阈值，来控制树的深度，或者控制节点的个数，在节点开始划分之前就进行操作，进而防止过拟合现象。后者是自底向上对非叶节点进行考察，如果这个内部节点换成叶节点能提升决策树的泛化能力，那就把它换掉。</p></li><li><p>运用交叉验证的方法选择合适的参数。</p></li><li><p>通过模型集成的方法（Bagging-parallel&#x2F;Boosting-serial），基于决策树构建更复杂的模型</p></li></ul><h2 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h2><h3 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h3><p>分割准则：分割后两个区域的MSE的和最小</p><p>假设$n$个样本$D&#x3D;{(x_1,y_1),(x_2,y_2),…,(x_n,y_n)}$，$x$是$d$维的（$d$个特征），选取第$i$个特征$d_i$的取值$s$作为划分两个区域的阈值,$R_1&#x3D;{y_i|x_{i,d_i}}\leq s$，$R_2&#x3D;{y_i|x_{i,d_i}}&gt; s$，每个区域内<strong>样本$y_i$的均值</strong>作为该区域的预测值，计算两个区域的样本真实值和预测值的平方误差之和。遍历每一个特征的每一个样本的取值，选择使得平方误差最小的取值，使用该值将样本分成两个区域，对这两个区域继续上面的步骤，一致递归生成，直到满足停止条件。</p><h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><ol><li><p>选择最优切分变量$d_i$以及切分点$s$，求解<br>$$<br>\underset{d_i,s}{\min}{\underset{x_i\in R_1 (d_i, s)}{\min}(y_i-c_1)^2+\underset{x_i\in R_2 (d_i, s)}{\min}(y_i-c_2)^2}<br>$$<br>遍历所有的特征维度$d_i$ ，固定$d_i$，遍历样本在特征$d_i$处的取值s，使得式子最小。</p></li><li><p>根据选取的$(d_i,s)$将样本划分成两个区域，计算两个区域的平方误差</p></li><li><p>选取使得式（1）最小的 （）（��,�） 将样本划分成两个区域，每个区域的预测值是所有样本y值的均值（根据平方误差的导数为0可得）。</p></li></ol><p>4）对于两个子区域继续调用1），2），3），直到满足停止条件。</p><p>5）最后划分为M区域 �1,�2……�� ，生成决策树</p><p>(4)�(�)&#x3D;∑�&#x3D;1����(����)</p><h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2>]]></content>
    
    
    <categories>
      
      <category>计算机</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>聚类</title>
    <link href="/2023/03/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%81%9A%E7%B1%BB/"/>
    <url>/2023/03/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%81%9A%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h1><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><ul><li>基于划分</li><li>基于层次</li><li>基于密度</li><li>基于网格</li><li>基于模型</li></ul><h3 id="基于划分"><a href="#基于划分" class="headerlink" title="基于划分"></a>基于划分</h3><ul><li><p>代表算法：K-means</p></li><li><p>优点：收敛速度快</p></li><li><p>缺点：要求类别数目 k 可以合理地估计，并且初始中心的选择和噪声会对聚类结果产生很大影响</p></li></ul><h4 id="K-means-vs-KNN"><a href="#K-means-vs-KNN" class="headerlink" title="K-means vs KNN"></a>K-means vs KNN</h4><ul><li><p>K-means：聚类，无监督</p><ol><li>随机选择k个样本作为初始聚类中心 a&#x3D;a1,a2,…ak ；</li><li>针对数据集中每个样本$x_i$ 计算它到 k 个聚类中心的距离并将其分到距离最小的聚类中心所对应的类中；</li><li>针对每个类别$a_j$ ，重新计算它的聚类中心$a_j&#x3D;\frac{1}{|ci|}\sum \limits_{x∈c_i}x$（即属于该类的所有样本的质心）；</li><li>重复上面2、3两步，直到达到某个中止条件（迭代次数、最小误差变化等）</li></ol><p>优点：</p><ul><li>容易理解，聚类效果不错，虽然是局部最优， 但往往局部最优就够了；</li><li>处理大数据集的时候，该算法可以保证较好的伸缩性；</li><li>当簇近似高斯分布的时候，效果非常不错；</li><li>算法复杂度低。</li></ul><p>缺点：</p><ul><li>K 值需要人为设定，不同 K 值得到的结果不一样；</li><li>对初始的簇中心敏感，不同选取方式会得到不同结果；</li><li>对异常值敏感；</li><li>不适合太离散的分类、样本类别不平衡的分类、非凸形状的分类。</li></ul></li><li><p>KNN：分类&#x2F;回归，有监督</p><p>将预测点与所有点距离进行计算，然后保存并排序，选出前面K个值看看哪些类别比较多，则预测的点属于哪类</p><p>优点：</p><ul><li>简单易用，相比其他算法，KNN算是比较简洁明了的算法。即使没有很高的数学基础也能搞清楚它的原理。</li><li>模型训练时间快，上面说到KNN算法是惰性的，这里也就不再过多讲述。<br>预测效果好。</li><li>对异常值不敏感</li></ul><p>缺点：</p><ul><li>对内存要求较高，因为该算法存储了所有训练数据</li><li>对不相关的功能和数据规模敏感</li></ul></li></ul><h4 id="KNN-K值选取"><a href="#KNN-K值选取" class="headerlink" title="KNN-K值选取"></a>KNN-K值选取</h4><p>从选取一个较小的K值开始，不断增加K的值，然后计算验证集合的方差，最终找到一个比较合适的K值</p><h3 id="基于层次"><a href="#基于层次" class="headerlink" title="基于层次"></a>基于层次</h3><p>对给定的数据进行层次分解，直到满足某种条件为止。分为自底向上法（AGNES）和自顶向下法（DIANA）</p><ul><li>优点：距离和规则的相似度容易定义，限制少，不需要预先制定簇的个数，可以发现簇的层次关系</li><li>缺点：计算复杂度太高，奇异值也能产生很大影响，算法很可能聚类成链状</li></ul><h3 id="基于密度"><a href="#基于密度" class="headerlink" title="基于密度"></a>基于密度</h3><p>寻找被低密度区域分离的高密度区域。与基于距离的聚类算法不同的是，基于距离的聚类算法的聚类结果是球状（凸）的簇，而基于密度的聚类算法可以发现任意形状的簇。基于密度的聚类方法是从数据对象分布区域的密度着手的。如果给定类中的数据对象在给定的范围区域中，则数据对象的密度超过某一阈值就继续聚类。这种方法通过连接密度较大的区域，能够形成不同形状的簇，而且可以消除孤立点和噪声对聚类质量的影响，以及发现任意形状的簇</p><h4 id="OPTICS"><a href="#OPTICS" class="headerlink" title="OPTICS"></a>OPTICS</h4><p>OPTICS（Ordering Points To Identify the Clustering Structure）是一种密度聚类算法，用于发现任意形状和任意密度的聚类结构。它可以处理高维数据和噪声数据，同时不需要预先指定簇的数量。</p><p>OPTICS算法的主要思想是，对于每个数据点，通过计算其与周围点的距离来评估其密度，并根据密度大小将其分类为核心点、边界点或噪声点。接着，从核心点开始构建聚类簇，通过对距离和密度进行扫描，将相邻的核心点分配到同一个簇中。最终，OPTICS算法可以得到一个聚类结构图，其中每个簇对应一个局部密度较高的区域。</p><p>OPTICS算法有一些优点。首先，它可以自适应地发现不同形状和密度的聚类结构，而不需要事先知道簇的数量。其次，它可以处理噪声数据和高维数据。此外，它不需要预先设置距离阈值，因此可以灵活地处理不同密度的数据。</p><p>然而，OPTICS算法也存在一些缺点。首先，它的计算复杂度较高，因此对于大规模数据集，其性能可能较差。其次，其结果可能受到参数设置的影响，例如邻域大小等。因此，在使用OPTICS算法时，需要根据具体情况进行参数调整和结果评估。</p><h3 id="基于网格"><a href="#基于网格" class="headerlink" title="基于网格"></a>基于网格</h3><p>将空间量化为有限数目的单元，可以形成一个网格结构，所有聚类都在网格上进行。基本思想就是将每个属性的可能值分割成许多相邻的区间，并创建网格单元的集合。每个对象落入一个网格单元，网格单元对应的属性空间包含该对象的值</p><ul><li>优点：处理速度快，其处理时间独立于数据对象数，而仅依赖于量化空间中的每一维的单元数</li><li>缺点：只能发现边界是水平或垂直的簇，而不能检测到斜边界。另外，在处理高维数据时，网格单元的数目会随着属性维数的增长而成指数级增长</li></ul><h3 id="基于模型"><a href="#基于模型" class="headerlink" title="基于模型"></a>基于模型</h3><p>试图优化给定的数据和某些数学模型之间的适应性的。该方法给每一个簇假定了一个模型，然后寻找数据对给定模型的最佳拟合。假定的模型可能是代表数据对象在空间分布情况的密度函数或者其他函数。这种方法的基本原理就是假定目标数据集是由一系列潜在的概率分布所决定的。簇的数目是基于标准的统计数字自动决定的，噪声或孤立点也是通过统计数字来分析的。基于模型的聚类方法试图优化给定的数据和某些数据模型之间的适应性</p>]]></content>
    
    
    <categories>
      
      <category>计算机</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
